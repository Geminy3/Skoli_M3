Qu'est-ce que la simulation sociale ?
Titulaire d’un master « Informatique et Sciences Humaines » et d’un master de littérature numérique, Arthur Lefèvre prépare une thèse à Paris 8 sur la génération automatique de texte à partir de mondes simulés. Il propose ici une réflexion critique sur les perspectives de la simulation sociale qu’il a notamment développé dans l’article « Simulation sociale et simulacre structural ».

Quelle définition donneriez-vous de la simulation sociale ? L’objectif de la simulation sociale est de construire des modèles d’une situation sociale à partir d’agents autonomes, c’est-à-dire des processus informatiques qui sont indépendants les uns par rapport aux autres et qui interagissent dans le même environnement. Ou dit autrement, elle simule une macrostructure à partir de microstructures en interaction. Ces systèmes de simulation dits « multi-agents » sont une application spécifique de l’informatique distribuée qui répartit les opérations d’un même calcul entre des processus différents travaillant en parallèle. C’est une approche micro qui cherche à sortir des grands systèmes d’équations de la modélisation mathématique classique qui ne permet pas de saisir les comportements individuels. Elle n’est pas totalement indépendante de la dimension macro sur laquelle elle vient plutôt se greffer : une simulation cherche à reconstruire les comportements individuels qui pourraient amener à une situation bien connue au niveau macro. L’évaluation de ses résultats se fait alors au niveau macro via les outils des modèles classiques, comme le recours aux statistiques pour évaluer le comportement du système par rapport à sa contrepartie réelle, donc valider le comportement implémenté des agents. Pour l’instant, il y a toujours une concurrence entre la simulation sociale qui commence à faire sa place, mais a encore besoin de se différencier, et les approches de modélisation statistique macro bien connues et rodées.Comment les disciplines de sciences humaines et sociales (SHS) se sont-elles appropriées cet outil issu des sciences dures ?  La diffusion reste assez faible. La simulation multi-agents a longtemps intéressé principalement les biologistes, les mathématiciens, les informaticiens et les physiciens. Puis, il y a eu la démarche d’archéologie rétrospective sur les populations amérindiennes Anasazis aux Etats-Unis qui a suscité beaucoup d’intérêt suite à ses résultats spectaculaires. Cette population a disparu au début du 15ème siècle pour des raisons inconnues et seules subsistaient des données sur leur organisation spatiale.  Les systèmes multi-agents ont l’avantage de pouvoir intégrer des données qualitatives ?  C’est une avancée très récente. La difficulté est d’arriver à donner une forme quantitative aux données qualitatives pour les intégrer au modèle informatique. Pendant longtemps, les questions qualitatives ont été repoussées sous prétexte qu’elles manquaient de scientificité. Mais comment justifier de négliger ces aspects sous prétexte qu’ils ne rentrent pas dans la machine ? Si on étudie la société, il n’est pas possible d’éluder des pans de sa réalité ! Le Journal of Artificial Societies and Social Simulation a d’ailleurs consacré un numéro spécial à la question. Je ne sais pas l’impact que ça aura sur la simulation à l’avenir, mais les chercheurs sont conscients du problème et veulent y remédier.Dans quels cas est-ce pertinent de recourir à une simulation sociale ?  En matière de recherche, par exemple en sociologie, je ne suis pas sûr que ce soit très utile, hormis à des fins de communication. En déterminant quels comportements ont permis d’arriver à la situation macro étudiée, une simulation réussie permettrait sans doute d’aider à la construction d’un modèle formel et à son exposé. Mais cela ne permet pas de construire une enquête ou d’alimenter le travail de sociologie lui-même. En matière de prospective ou d’aide à la décision, il me semble que le problème est renversé. Si le souhaitable est déjà défini, le modèle peut servir à déterminer quels comportements permettent d’y arriver. Le risque est de chercher à trouver les moyens d’influer sur les comportements individuels pour aller dans ce sens, voire de les policer. Pour que cela fonctionne, il faudrait alors une instance disciplinaire qui garantisse que les individus se comportent de telle ou telle façon dans la vie réelle. C’est concevable à l’échelle d’une équipe de quelques personnes mais il est impossible de policer les comportements à l’échelle d’une ville, et c’est antinomique avec l’idée de pouvoirs publics démocratiques. Un meilleur usage de la simulation sociale est d’essayer d’anticiper les conséquences d’une situation ou de s’interroger sur les effets de changements. Cette démarche peut partir des comportements observés et les projeter à plus long terme ou face à divers événements comme la construction d’un nouveau bâtiment, le changement de la régulation du travail, etc. Cela nécessite un modèle fiable des comportements individuels, c’est-à-dire un modèle qui puisse au moins expliquer le présent avant d’explorer des hypothèses sur le futur.Est-ce possible de prendre en compte l’irrationalité, les émotions, la question des valeurs ? Les systèmes multi-agents peuvent intégrer les limitations de la rationalité mais le vrai problème est plutôt celui des présupposés idéologiques que chacun met dans le modèle. Chaque discipline, voire en son sein, chaque école a sa propre philosophie et donc des présupposés. Il y a autant d’écoles de simulation multi-agent que de modélisateurs, ou de commanditaires. Les simulations économiques ont ainsi des partis pris importants puisqu’elles considèrent les agents uniquement comme des agents économiques, se référant à des « règles » du marché et cherchant à maximiser une notion de satisfaction. Au-delà du fait que l’État est le plus souvent absent du système économique simulé, les gens ne sont pas de purs agents économiques. Ils font d’autres choses dans la vie et prennent des décisions « irrationnelles » économiquement, mais qui font sens dans d’autres systèmes, qui ne sont même pas forcément des systèmes de maximisation. De même, les pouvoirs publics ne seront pas intéressés par un modèle académique car ils ont leurs présupposés sur ce que doit être l’action publique, ce que sont les usagers… Ces présupposés sous-tendent le modèle sans le dire. Ce sont des éléments cachés, que seul le code permet d’identifierLes modèles de modélisation urbaine qui reposent sur des données quantitatives (occupation des sols, mobilité, caractéristiques socio-économiques des populations du territoire modélisé) dissimulent aussi de tels présupposés ?  Par définition oui, puisque ce type de modèle résume les agents réels à leurs comportements vis-à-vis du transport, de l’économie… Ce sont des composantes à considérer mais il peut aussi y avoir des éléments qui ne sont pas mesurés ou pas mesurables. Par exemple, des questions de rivalité entre quartiers ou de différence sociale entre un quartier bourgeois et un autre plus populaire. Si un nouveau pont relie ces quartiers, la mobilité sera améliorée mais peut-être aussi la qualité des bagarres ou de la violence sociale face à une mixité non voulue. Aucun aménagement n’est neutre : ce n’est pas pareil de construire un pont à Lyon aujourd’hui que de construire un pont entre une communauté Serbe et une communauté Croate en 1995. Il n’est pas possible d’évacuer la violence du social comme ça ! Il y a toujours un point de tension, un potentiel explosif absolument impossible à effacer. Toute démarche de simulation ou de modélisation devrait être accompagnée par un sociologue ou un philosophe capable de questionner les présupposés ?  Oui, le plus gros risque serait de laisser ça aux informaticiens ! Ils ne sont pas formés à cela et mobilisent une philosophie spontanée, « le bon sens ». Questionner ce fameux bon sens est justement le rôle des sociologues et des philosophes. Par sa nature informatique, la simulation présente l’image d’une technique neutre alors que ces présupposés sont inévitables et empêchent cette neutralité. Il est important de lutter contre cette couche idéologique, d’autant plus que l’utilisation prospective va se développer. L’important est d’avoir un débat sociologique sur le modèle abstrait et pas seulement un débat technique sur le bon rendu du modèle dans le code. La simulation est un discours sur le réel même si elle a des apparences de nouvelle technologie éblouissante d’objectivité technique !Le rendu 3D des modèles est souvent avancé comme permettant de rendre plus accessible et partageable les résultats de la simulation, notamment avec des néophytes. C’est une posture trompeuse ?   L’argument de la 3D s’apparente pour moi à de la poudre aux yeux. Malgré les simulations visuelles, le modèle reste un système très abstrait et, dans l’abstraction, la 3D relève davantage de l’argument de vente que de la science. Bien sûr, cela peut permettre aux gens qui vivent sur le territoire de reconnaître les endroits modélisés et de faire un retour si le comportement de l’endroit modélisé diffère de son comportement réel. Cela peut aider à calibrer et valider le modèle. Mais cela peut faire passer au second plan la manière dont les agents ont été programmés et pourquoi. Il faut avoir l’esprit critique et garder en tête que la partie intéressante, ce n’est pas la 3D, mais bien le modèle informatique, son code et ses présupposés. Ces questions ne doivent pas rester en arrière-plan de la démarche d’explicitation du modèle, c’en est le cœur.En nécessitant d’impliquer l’ensemble des acteurs concernés afin qu’ils partagent leurs réalités sur l’objet modélisé, la démarche de simulation semble un bon outil de démocratie participative ?  Oui, je pense même que c’est sa vertu principale si le public est vraiment inclus dans la co-construction du modèle. La construction d’un objet unique s’accompagne de l’élaboration d’un langage et d’un espace de discussion communs, lieu de partage des points de vue conflictuels. Même si des désaccords subsistent à la fin sur les choix à faire, les participants sont éventuellement d’accord sur comment ça marche. Je pense à une expérience au Sénégal, sur la simulation de ressources aquatiques pour l’irrigation en fonction du comportement des agriculteurs. Le modèle a été construit avec la population locale. Cela demande des allers-retours permanents pour construire le modèle au plus juste. C’était un jeu de rôle intéressant et très pédagogique car il construit une relation entre les acteurs locaux et leur permet de comprendre ce qui se passe globalement, pour les récoltes et l’état des rivières, en fonction de leurs comportements individuels. De plus, la présence d’un chercheur s’apparente à celle d’un arbitre. Il prend en considération la parole de chaque acteur sur le phénomène étudié et sur la fidélité de sa reproduction dans le modèle.  Chacun peut dire que cela ne marche pas comme ça, mais l’autorité du chercheur lisse et régule les potentiels conflits en identifiant les points à négocier, sans que lui-même soit « expert » de la réalité expérimentée. Le modèle en soi ne suffit pas à faire de la médiation entre les acteurs. C’est juste un support de dialogue qui nécessite la présence d’un tiers régulateur qui n’empiète pas sur les expertises contradictoires des acteurs sur leur propre expérience du système.Les villes sont de plus en plus nombreuses à modéliser leur territoire. Pour vous, quelles sont les limites de cet outil en matière d’action publique ?  En Europe, la tendance est à la technicisation de la politique. Face à cet outil, je pense important de garder en tête que ce qui est construit n’est qu’une simulation qui tronque la réalité. Donc, il faut être explicite sur ce qui est inclus et ce qui est exclu. Faire une simulation avec les variables socio-économiques d’un quartier peut être intéressant du moment qu’il est annoncé dès le départ que tout le reste a été tronqué. Ensuite, le commanditaire, ici les pouvoirs publics, a ses propres idées, ses présupposés qui sont une manière de voir la réalité. La subjectivité du commanditaire le prédispose à accepter telle fiction ou telle autre. Est-il en capacité d’intégrer des agents qui auraient des comportements marginaux comme la triche, la corruption… À partir du moment où un agent du modèle est infaillible, ce n’est plus un agent humain. Il faut donc construire un modèle dans lequel ce genre de comportements peut arriver. Par exemple, une simulation de retraitement des déchets en informatique prenait en compte le fait que les patrons employaient illégalement des enfants et pouvaient corrompre l’inspecteur du travail. Mais est-ce qu’un pouvoir public est prêt à construire des modèles dans lesquels les inspections du travail ou tout autre agent public sont corruptibles ?En matière de modélisation urbaine, l’intérêt de la simulation est de pouvoir repérer la tendance globale émergente. L’important est donc que 90% des gens se comportent comme dans le modèle. Peu importe ce que font les 10% à la marge car cela n’influe pas tellement sur les résultats du modèle ni sur sa capacité prédictive. Qu’en pensez-vous ?  Joshua M. Epstein disait que la prédiction ne devait pas être l’objectif principal de la simulation. En physique, un objet lancé en l’air va retomber. Mais ce sont des postures qui peinent à s’appliquer au social... Plus les modèles sont complexes, plus ils sont sensibles à la probabilité d’un accident, d’un évènement aux conséquences imprévisibles. Ce n’est pas un accident qui va être résorbé par le modèle, mais bien un accident qui change ensuite le comportement des agents dans le même modèle. Or, le modèle ne pourra pas s’adapter puisque ce type d’accident n’est pas prévu. Finalement, plus le modèle est complexe, plus les 10% de la marge sont importants. Le modèle ne peut pas être exhaustif mais il faut toujours être conscient que rejeter des comportements à la marge, c’est enlever une grande partie de l’aléatoire et du risque réel. Par ailleurs, le temps du modèle se mesure en « ticks » : à chaque tick, chaque agent agit. À la fin de la simulation, on sait combien de ticks sont nécessaires pour parvenir au résultat. Mais comme l’espace, le temps de la simulation est abstrait, cela ne nous dit pas combien de temps « réel » s’est écoulé, seulement le nombre de ticks qu’un modèle prend pour converger vers une situation.  C’est un temps qui n’est pas mesurable en termes réels parce que le modèle simplifie les choses : certains éléments circulent plus vite, d’autres sont plus stables… Au final, il est impossible de savoir combien de temps cette évolution prendra réellement : 1000 ticks correspondent-ils à 200 ans, deux jours... ? Encore une fois, c’est une part d’imprévisible qu’il faut chercher à garder à l’esprit parce que la simulation ne rend pas compte de ce qui a été simplifié, donc des possibilités d’accident retirées.Dans une perspective d’aide à la décision, est-ce nécessaire de comprendre les mécanismes comportementaux ou peut-il y avoir une boîte noire si les données de sortie semblent réalistes ?  Surtout pas ! Cela voudrait dire qu’on fait l’impasse sur les présupposés. Or les résultats ne peuvent être lus indépendamment de ces derniers. Se contenter des résultats pourrait inciter les modélisateurs à ne fournir que les résultats attendus puisque personne ne pourra vérifier comment ils sont produits. Et quand cela ne marche pas tout de suite, il peut être très difficile de trouver pourquoi surtout quand le modèle est très complexe. Des erreurs peuvent se corriger entre elles par « hasard », et il devient alors très difficile de savoir qu’il y a une erreur et où elle se trouve. L’effet « boîte noire » est toujours un problème.Pourtant les modèles de prédiction en matière de criminologie adoptés par de plus en plus de villes reposent bien sur des boites noires pour aider l’action publique ? Ils prennent en compte le local mais il faut être global. Souvent, ces modèles sont utilisés pour de la prévention. La délinquance baisse parce que des équipes de police se sont déplacées à cet endroit. En reproduisant le problème, la simulation donne quelque chose d’immédiatement lisible. Les pouvoirs publics développent un modèle qui leur permet d’arriver à la situation souhaitée mais sans s’intéresser aux causes, au fait que des gens ont besoin de voler pour vivre par exemple. Optimiser la sécurité par des calculs statistiques sans agir sur le comportement global de la société n’est pas suffisant.  A terme, la délinquance se déplace ailleurs. Les délinquants vont finir par comprendre le fonctionnement du modèle et le jouer contre la police locale.Le « big data » peut-il révolutionner la simulation et la compréhension des phénomènes ?  Pour l’instant, même les grosses agences, comme la National Security Agency aux USA, avouent qu’elles ne savent pas bien comment exploiter toutes ces données disponibles sur tout le monde. Les données ne sont pas homogènes, ni utilisables telles quelles et ne servent pas forcément à faire des corrélations. L’idée de faire tourner plein de données hétérogènes dans un même modèle me semble peu plausible : il faut bien coder à un moment donné ! Les données ne sont pas des objets qui se baladent et qu’il est possible d’associer au petit bonheur la chance. Pour faire modèle, elles doivent être reliées par des structures qui interagissent de manière précise pour créer du sens. Supposons que les objets n’aient aucun rapport entre eux, dans un modèle, il faut quand même qu’il y ait une instance qui tienne les objets ensemble pour les faire interagir. Donc, une structure qui fait du sens à partir de leur hétérogénéité. Le codage d’une simulation repose sur du structuralisme, même si on en n’a pas conscience ! Oui, la simulation part du micro mais du micro dans une structure macro, les agents et le système sont indissociables. Dans un avenir lointain, il serait peut-être possible d’imaginer partir d’une masse de données hétérogènes et construire une intelligence artificielle capable de construire un modèle qui permette d’arriver à ces données-là, mais on en est clairement très loin. Vous pensez qu’une nouvelle discipline pourrait émerger ? Pour l’instant, cela reste clairement dans l’informatique. Le code demande encore trop de compétences techniques, mais ce serait bien qu’il y ait des masters croisés sociologie/informatique. Le problème est celui du temps d’enseignement de chacune des matières pour avoir vraiment des compétences solides dans les deux domaines. De plus, sociologues et informaticiens ont des histoires scientifiques complètement différentes, de même que leur vision de ce qu’est la recherche et de comment la mener. Il faudrait une histoire longue pour se rapprocher mais ça pourrait être intéressant. 