Les apports des neurosciences au monde de la robotique
Karim Jerbi est chercheur au Centre de Recherche en Neurosciences de Lyon où il travaille en particulier sur la connectivité cérébrale et les interfaces cerveau-machine. Nous l'avons interrogé sur les apports des neurosciences au monde de la robotique. S'inspirer de l'intelligence biologique pour créer de l'intelligence artificielle semble en effet pertinent dans certains cas, mais les limites à lever sont encore nombreuses avant de concevoir des robots susceptibles d'aider des personnes handicapées ou valides au quotidien. Moins médiatisées, les interfaces cerveau-machine permettent de mettre en relation l'individu et son activité cérébrale. Elles semblent offrir des perspectives prometteuses pour aider les personnes handicapées à communiquer ou encore rééduquer l'attention des enfants souffrant de déficits attentionnels...Cette interview s'inscrit dans le cadre d'une large étude sur la robotique de service conduite par la Direction de la prospective du Grand Lyon et son réseau de veille.

Comment les neurosciences abordent-elles la question des robots et des machines intelligentes ? Les neurosciences abordent ces sujets essentiellement de deux manières. D'une part, elles étudient le fonctionnement du cerveau humain, et celui-ci peut servir de modèle pour les robots. D'autre part, elles s'intéressent aux conséquences des interactions homme-machine sur le cerveau humain. Que peuvent apporter les neurosciences aux professionnels de la robotique ?Il y a un parallèle à tirer entre l'intelligence artificielle et l'intelligence des systèmes biologiques. C'est un point qui est important et qui a été assez négligé à mon sens. Il n'y a pas suffisamment d'interactions entre les chercheurs de ces deux champs. La neurobotique est le point de rencontre entre la robotique, les neurosciences et l'intelligence artificielle. Cette discipline encore émergente se développe de plus en plus et contribuera à améliorer les recherches en matière de robotique.Ensuite, il faut distinguer les types de « robots », même si les frontières sont assez floues : les robots autonomes et les interfaces homme-machine. Il peut s'agir par exemple, de prothèses de bras robotisées que l'on interface avec le corps d'un patient, soit directement aux muscles, soit au cerveau. Dans le domaine des interfaces cerveau-machine, le Centre de Recherche en Neurosciences de Lyon fait partie des leaders en France. Mais les neurosciences s'intéressent aux deux types de « robots ». Par exemple, dans le cas du robot autonome qui doit se déplacer, la robotique apporte des algorithmes pour optimiser les déplacements dans l'espace mais on peut aussi s'inspirer du fonctionnement neurobiologique de l'humain. Dans les deux cas (robot autonome ou interface) et c'est sans doute ce qui est le plus intéressant pour l'avenir, la question de l'apprentissage se pose : le robot doit pouvoir apprendre de son environnement. Encore une fois, on peut s'inspirer de l'humain, qui fait cela très bien, et se tourner vers les neurosciences pour envisager quels modèles humains d'apprentissage et d'interaction avec l'environnement permettent d'améliorer l'apprentissage des robots. Que manque-t-il pour que le croisement des neurosciences et de la robotique prenne plus d'ampleur ?Les choses seraient beaucoup plus faciles évidemment si l'on connaissait parfaitement le fonctionnement du cerveau humain et si l'on savait le reproduire. Ce n'est bien sûr pas le cas, il reste encore beaucoup de zones d'ombre. Mais l'intérêt grandit à la fois pour les interfaces homme-machine, pour la robotique et pour la neurobotique. Cela entrainera davantage d'interactions entre les chercheurs de ces différentes disciplines. Ces partages de connaissances et ces collaborations serviront aux roboticiens, aux spécialistes de l'intelligence artificielle comme aux neuroscientifiques. Il faut espérer aussi que ces domaines en pleine expansion et interdisciplinaires bénéficient davantage de financements à l'avenir car ils sont susceptibles d'apporter des réponses à la société aussi bien pour faciliter notre vie de tous les jours que pour aider des patients. On peut citer par exemple la neuroréhabilitation qui concerne la réhabilitation des affections du système nerveux central (traumatisme cranio-cérébral, accident vasculaire cérébral, encéphalopathies, maladies inflammatoires, maladies neuro-dégénératives, traumatisme médullaire…) et du système nerveux périphérique (maladies neuro-musculaires, myopathie…) ; la neuroréhabilitation a aussi pour objectif de prévenir la maladie ou des complications qui pourraient survenir. S'inspirer du cerveau humain pour concevoir des robots Le cerveau humain peut servir de modèle pour concevoir des robots. Quels sont les avantages et les limites de cette logique ? Le cerveau humain peut en effet servir de modèle pour concevoir des robots : il s'agit d'une piste très ambitieuse mais qui pourrait rapporter beaucoup. Les connaissances du cerveau humain ont considérablement progressé ces cinquante dernières années et même s'il y a encore beaucoup d'incertitudes, il est d'ores et déjà possible de créer des logarithmes s'inspirant des mécanismes humains, on parle de « biologically inspired algorithms ».Mais cette logique n'est pas pertinente pour tous les types de robots, il faut s'adapter aux besoins. S'inspirer de l'humain a du sens lorsqu'il s'agit de robots destinés à interagir directement avec l'humain : cela favorisera vraisemblablement les interactions, la communication, l'appropriation du robot, son usage... Mais dans le cas de robots destinés à travailler en milieu hostile, il est plus utile de privilégier d'autres performances : la détectabilité de tel ou tel risque, l'autonomie énergétique, la mobilité, etc. Bien sûr, plus on comprendra le cerveau humain, plus il sera facile de distinguer ce qui est souhaitable de reproduire ou non pour faire fonctionner un robot. Pouvez-vous nous donner un exemple où il est judicieux de reproduire le fonctionnement humain au sein d'un robot ?Le mode d'interaction avec l'environnement est un bon exemple. Différents modèles peuvent être utilisés : un modèle interne basé sur l'apprentissage (dans ce cas, le robot apprend que la brique de lait peut être vide, pleine ou en partie pleine et apprend les différents gestes adaptés à tous les cas de figure), un modèle basé sur le feedback1  (dans ce cas, le robot prend en compte l'environnement en temps réel et s'autocorrige), des modèles hybrides, etc.Ces modèles sont étudiés au sein du laboratoire par Christina Schmitz qui s'intéressent à la construction des représentations de l'action chez l'enfant. La construction de multiples représentations -des caractéristiques du corps, du monde extérieur et de leurs interactions réciproques- est nécessaire pour permettre la perception et l'action (soulever une brique de lait dans notre exemple). Or, les enfants autistes montrent un déficit de la fonction d'anticipation qui indiquerait une atteinte de la construction des représentations de l'action. Cette atteinte freinerait leur développement sensori-moteur et cognitif. En d'autres termes, les enfants autistes ne raisonneraient pas selon un modèle interne, mais en revanche, ils savent très bien s'auto-corriger. Leur fonctionnement perceptivo-moteur s'apparenterait davantage au modèle basé sur le feedback. Il s'agit là d'une hypothèse de travail en cours d'exploration par notre centre et que je cite ici pour illustrer comment les recherches en neurosciences fondamentales et cliniques peuvent nous renseigner sur les modes opératoires de boucles sensorimotrices qui peuvent optimiser l'efficacité de notre interaction avec l'environnement. Ces connaissances pourraient nous aider à améliorer les robots de demain. Quels sont les freins actuels à la recherche au croisement des neurosciences et de la robotique ? Se situent-ils au niveau des connaissances du cerveau humain ou des difficultés à le reproduire au sein des robots ?Il y a plusieurs difficultés : on ne connait pas encore parfaitement le fonctionnement du cerveau, on a des difficultés à reproduire artificiellement ce fonctionnement et les professionnels concernés n'ont pas la même culture. Le projet européen Neurobotics, développé dans le cadre du 6e programme cadre de la commission européenne entre 2004 et 2007, était un des premiers projets à large échelle permettant de réunir des professionnels des neurosciences et de la robotique. L'ambition était de produire des robots plus proches des neurosciences en termes de fonctionnement. On a pu aussi mesurer au cours de cette expérience combien les roboticiens et les neuroscientifiques ne parlaient pas le même langage. D'autres projets ont vu le jour depuis, mais nous avons du chemin à parcourir pour progresser ensemble.Les neurosciences computationnelles sont aujourd'hui bien reconnues et joueront vraisemblablement un rôle important à l'avenir à l'interface des neurosciences et de la robotique. Il est par exemple possible de concevoir des systèmes de contrôle pour des robots qui s'appuient sur les connaissances issues des neurosciences computationnelles et des modèles de traitement de l'information chez l'Homme. La mise en place d'algorithmes qui génèrent des modèles similaires à ceux des neurosciences devra bien sûr être adaptée au contexte robotique donné.On pourra certainement reproduire plus d'éléments du fonctionnement du cerveau humain à l'avenir. C'était un peu l'ambition du « Blue Brain Project » lancé en 2005 par l'EPFL (Ecole Polytechnique Fédérale de Lausanne) et IBM : l'idée était de modéliser le cerveau mais avec un niveau de détail jamais atteint auparavant. Ceci dit, je doute de nos capacités à élucider entièrement les mystères du fonctionnement cérébral. Les approches qui visent à reproduire même partiellement le fonctionnement du cerveau restent utiles pour augmenter nos connaissances et améliorer les robots destinés à nous aider dans la vie quotidienne. Mais les robots ne sont pas la seule solution, loin de là. Les interfaces cerveau-machine offrent des applications médicales très larges. Que peut-on attendre des interfaces cerveau-machine ?Les interfaces cerveau-machine permettent à un individu de communiquer avec son environnement, via un ordinateur, sans l'intervention de ses muscles et de ses nerfs. L'interface comprend un système d'acquisition et de traitements des signaux cérébraux (activité électrique des neurones). Elle est ensuite capable de les classer, de les traduire et de les transmettre à un système de commande numérique ou mécanique comme un clavier, un fauteuil roulant, une prothèse, etc. Concrètement, dans le développement des interfaces cerveau-machine, on peut distinguer les méthodes permettant l'enregistrement de l'activité cérébrale de manière non invasive et celles permettant l'enregistrement de l'activité cérébrale de manière invasive. Elles auront des applications différentes.Dans le cas d'un protocole non invasif, on utilise des électrodes EEG (d'électroencéphalographie) ou des capteurs MEG (de magnétoencéphalographie) situés au niveau du cuir chevelu du sujet afin de mesurer l'activité cérébrale en temps réel. Des logiciels de classification des signaux nous permettent de décoder l'état cérébral du sujet et son intention afin de les communiquer à une machine. Ces systèmes permettent à des patients paralysés mais conscients de faire bouger le curseur sur un écran ou encore d'épeler un mot. Concrètement, on équipe le patient d'un casque à électrodes et on lui présente un écran où les lettres de l'alphabet s'illuminent les unes après les autres rapidement. Lorsque le patient voit sur l'écran la lettre qu'il souhaite, son cerveau génère un signal particulier qui est détecté par la machine. Il peut donc, lettre par lettre, mot à mot, écrire une phrase par la pensée. Nous avons une machine de ce type à Lyon, au CNRL, qui a été développé par Jérémie Mattout et Emmanuel Maby dans le cadre du projet OpenVibe, financé par l'Agence Nationale de la Recherche (ANR). Vous imaginez donc les applications potentielles d'aide à la communication pour tous les patients privés de leurs capacités à communiquer et à se mouvoir. Mais cela implique bien sûr que le patient souhaite utiliser cette technologie et puisse se concentrer.Dans le cas de méthode invasive, on enregistre l'activité cérébrale au sein même du cerveau. Cela implique l'implantation d'électrodes dans le cerveau, donc une chirurgie. Aujourd'hui, ces pratiques sont uniquement réalisées à titre expérimental. Nous travaillons avec les services des CHU de Lyon et de Grenoble traitant l'épilepsie et des patients volontaires souffrant d'épilepsies pharmacorésistantes, donc candidats à la chirurgie. Grâce à des électrodes implantées dans le cerveau et à des traitements des signaux ad hoc, on peut visualiser l'activité cérébrale du patient en temps réel. On peut par exemple représenter l'activité cérébrale par la position d'une boule sur un écran. Cette boule peut changer de position selon la fréquence de l'activité cérébrale : elle augmente par exemple lorsqu'on se sert de sa mémoire de travail pour faire du calcul mental. Sans parler, rien qu'en regardant la position de la boule sur l'écran, nous pouvions savoir si le patient se servait de sa mémoire de travail ou s'il était au repos. Ce système pourrait être utilisé par des patients pour des besoins de communication binaire, exprimer par exemple un oui ou un non. Ces interfaces cerveau-machine permettent aux patients de s'exprimer mais peuvent-elles aller au-delà... développer certaines facultés ou permettre à des patients de commander par leur pensée un interrupteur, la souris d'un ordinateur ou un fauteuil roulant ?Le chercheur Jean-Philippe Lachaux qui travaille aussi au CNRL a développé une interface qui s'appelle la « Brain TV ». Dans ce cas, ce dispositif permet aux patients de visualiser l'activité de leur cerveau sur un écran (des fréquences que nous aurons choisi). Cela permet d'explorer en temps réel le rôle fonctionnel de telle ou telle région du cerveau (le mouvement de la main, le calcul mental, etc.) et de proposer un retour visuel au sujet qui peut s'entraîner à modifier ce signal... On utilise cette stratégie de neurofeedback auprès d'enfants souffrant de déficits d'attention. Un exercice consiste à représenter l'activité cérébrale par l'image d'un petit poisson sautant hors de son bocal. L'enfant peut se concentrer et s'entraîner à le faire sauter de plus en plus haut. En visualisant ses progrès et via l'entraînement, il exerce et développe son attention.Soulignons que l'apprentissage en boucle fermée est un élément important des interfaces cerveau-machine : le sujet visualise son activité cérébrale, apprend à mieux contrôler ses signaux (en partie de manière inconsciente) et la machine apprend à mieux décoder les signaux. Par exemple, dans le cas du système permettant au patient d'épeler des mots, la machine peut apprendre le signal manifesté par le patient lorsqu'elle se trompe de lettre.Concernant la commande d'un mouvement, les choses sont plus complexes. Par exemple, dans le cas d'interfaces cerveau-machine non invasives, on travaille souvent avec des patients paralysés : ils imaginent le mouvement sans l'exécuter, plusieurs études ont montré qu'imaginer un mouvement et le réaliser sont assez proches en termes d'activité cérébrale. On décode donc assez bien ces intentions de mouvement lorsqu'il s'agit de trajectoire simple comme tendre la main. Mais cela est beaucoup plus difficile quand il s'agit de décoder une intention de trajectoire complexe comme une souris d'ordinateur. Certains chercheurs pensent que cela ne sera possible qu'en utilisant des méthodes invasives, qui sont beaucoup plus fines. Ce passage ou non à des méthodes invasives n'est pas neutre quand il s'agit du cerveau. Cela implique nécessairement de prendre en considération la dimension éthique de tels travaux...En effet, il n'est pas question d'implanter des électrodes dans le cerveau de personnes ne nécessitant pas d'intervention chirurgicale. On touche là à des questions éthiques pour lesquelles un vrai débat de société doit être ouvert : les interfaces cerveau-machine doivent-elles obligatoirement restées non invasives ? Ces méthodes non invasives ne risquent-elles pas d'être utilisées par des personnes en bonne santé à des fins tout autres que médicales ? Faut-il autoriser les méthodes invasives uniquement pour « réparer » l'homme et lui permettre de retrouver certaines facultés (comme cela se fait déjà avec certains patients parkinsoniens) et non pour « augmenter » les capacités humaines ?Une chose est sûre : ce n'est pas parce qu'on peut le faire qu'on doit obligatoirement le faire. Il ne faut pas craindre le futur, mais examiner les opportunités qu'offrent les robots et les interfaces cerveau-machine de manière raisonnable et responsable. Les conséquences des interactions homme-machines sur l'homme... Déléguer certaines actions à ces objets techniques n'est pas anodin. Quelles peuvent-être les conséquences de nos interactions croissantes avec des robots et des objets intelligents sur nos capacités cognitives ? Il faut tout d'abord rappeler que cela a toujours existé : depuis toujours, l'homme s'adapte à son environnement et aux objets techniques qui sont créés. Bien sûr, ces objets techniques que nous avons évoqué, robots et interfaces cerveau-machine, vont avoir un impact grandissant sur notre quotidien et donc sur notre façon d'interagir avec notre environnement. Mais la faculté sans doute la plus géniale du cerveau -sa plasticité- va lui permettre de s'adapter à tous ces changements. Il y a quelques années encore, on pensait que nous disposions d'un nombre déterminé de neurones, on sait aujourd'hui que les connections entre neurones changent en fonction de notre modes de vie, de nos actions, etc.La neuroplasticité a été très étudiée chez les musiciens : avec l'IRM, on a pu montré une modification anatomique, un épaississement de la matière grise dans certaines régions liées à la motricité, la manipulation régulière d'instruments de musique... et ceci est corrélé avec la durée de l'apprentissage. Mais ces modifications sont réversibles. On peut faire le parallèle avec un muscle qui se développe quand on l'entraîne régulièrement et qui diminue lorsqu'on cesse tout entraînement. L'entraînement cérébral est comparable : le fait d'interagir avec des objets nouveaux, de s'adapter à de nouvelles situations va nécessairement stimuler notre cerveau qui s'y adaptera très bien. Mais si nous déléguons certaines tâches à des machines, si nous cessons de nous entraîner, nous perdrons certaines capacités ou compétences à terme. Les futures générations ne sauront plus lire une carte ou calculer mentalement... Et elles n'apprendront bientôt plus ces tâches à leurs enfants. Ce potentiel inexploité sera-t-il perdu ?Non, je ne dirai pas cela : le potentiel est bien là mais il est dédié à d'autres tâches en fonction de nos besoins, dans l'environnement dans lequel nous évoluons. L'intelligence humaine ne va pas régresser à cause de l'évolution technologique. Ces facultés d'adaptation sont remarquables et essentielles à notre survie si nous raisonnons sur un temps long. Et puis, il faudra bien programmer ces machines qui mémoriseront, calculeront, chercheront des informations à notre place : ces connaissances ne sont donc pas perdues.L'important n'est-il pas de reconnaître que nos besoins et nos intérêts changent et qu'il est naturel d'évoluer et de nous adapter au mieux à l'environnement dans lequel nous vivons ? Nous pouvons faire le parallèle avec l'utilisation de l'ordinateur à des fins personnels puis dans le champ de l'éducation. Très décrié il y a quelques années, il a désormais trouvé sa place dans les établissements scolaires pour remplir certaines tâches qui répondent à des besoins (autres que des cours d'informatique). Nous pouvons d'ores et déjà nous interroger collectivement : comment utiliser les robots à des fins éducatives ?... car cela arrivera forcément un jour. Et cela ne sera pas nécessairement un robot androïde remplaçant le professeur, mais des systèmes de réalité virtuelle pour apprendre l'histoire, des interfaces cerveau-machine pour faire de la géométrie dans l'espace, etc. A l'inverse, ces robots et machines intelligentes nous permettront-elles indirectement de développer de nouvelles compétences ?Certainement, mais c'est une question difficile... peut-être sommes-nous plus capables que les générations précédentes de mener plusieurs tâches à la fois en démultipliant notre attention, peut-être sommes-nous plus créatifs qu'auparavant... mais je ne suis pas certain.Par contre, les interfaces cerveau-machine renouvellent d'ores et déjà notre potentiel créatif. Nous participons actuellement au montage d'un projet local « LOEC 2 » visant à croiser les neurosciences, l'ingénierie et l'art. Une partie de ce projet consiste à explorer la dynamique cérébrale en jeu dans la perception d'une œuvre d'art ou de la performance d'un artiste. Une autre est d'étudier si les interfaces cerveau-machine peuvent jouer un rôle dans la compréhension de mécanismes de création ou de perception d'une œuvre. On peut imaginer par exemple qu'un artiste utilise son activité cérébrale pour créer une œuvre via une interface cerveau-machine. En temps réel, il observe son processus de création, ceci modifie ses émotions et donc son activité cérébrale, l'œuvre progresse peu à peu. On peut imaginer aussi l'intervention de spectateurs équipées de casques portant des électrodes afin de les faire participer à l'œuvre en cours d'élaboration, influencer l'artiste, etc. Les possibilités sont immenses.---------------------------------------------------------------------1RétroactionLe Centre de Recherche en Neurosciences de Lyon (Inserm U1028 – CNRS UMR 5292) a été constitué le 1er janvier 2011. Il réunit 11 équipes de recherches aux compétences variées : neurobiologie, neurophysiologie, neuropharmacologie, neurosciences cliniques (neurologie, psychiatrie), neuroimagerie, neurosciences cognitives, neuropsychologie, psychologie cognitive, neurolinguistique, modélisation neuromimétique, intelligence artificielle. Ces équipes sont rattachées à l'Ecole Doctorale Neurosciences et cognition de l'Université de Lyon et accueillent chaque année des étudiants en Master-recherche en Neurosciences et en thèse. http://crnl.univ-lyon1.fr/ 