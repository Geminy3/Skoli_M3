9 QUESTIONS PIÈGES DU DÉVELOPPEMENT DURABLE (Archives)
Les débats sur le changement climatique, ses menaces pour notre planète, et l'impératif de développement durable conduisent invariablement aux mêmes interrogations : la biodiversité est-elle réellement menacée ? Sommes-nous vraiment responsables du changement climatique ? Peut-on concilier croissance économique et protection de l'environnement ? Sommes-nous trop nombreux sur Terre ? Etc. Certes, le sujet est particulièrement complexe, mais ces questions récurrentes ne révèlent-elles pas aussi nos difficultés à envisager notre part de responsabilité et des changements de nos modes de vie ? Afin de tordre le cou aux idées reçues et au scepticisme persistant, revenons sur quelques questions pièges du développement durable...
La biodiversité est-elle réellement menacée ? Si oui, est-ce si grave ?    La biodiversité ne désigne pas seulement la diversité des espèces mais également la diversité des gènes, c'est-à-dire des patrimoines génétiques au sein d'une même espèce, et la diversité des écosystèmes, c'est-à-dire des ensembles formés par les plantes, animaux, micro-organismes qui interagissent entre eux et avec le milieu dans lesquels ils vivent. Bien sûr, ces 3 niveaux sont inter-dépendants : une modification d'un écosystème peut favoriser certaines espèces au détriment d'autres. Certaines espèces seront plus à même de s'adapter à cette modification en raison de la diversité de leurs gènes et de leur transmission au sein de l'espèce. Alors, qu'en est-il des menaces pesant sur la biodiversité ? La situation est-elle dramatique ou bien considérablement exagérée par les défenseurs de l'environnement ?La diversité biologique n'a-t-elle pas toujours évolué au cours de l'histoire ?La biodiversité actuelle est le résultat d'une longue évolution naturelle : gènes, espèces et écosystèmes s'adaptent constamment, ou non, au monde changeant. Certains disparaissent, d'autres apparaissent. On estime actuellement que les espèces identifiées (1,7 million) ne représentent qu'environ 1% de toutes les espèces ayant vécu sur Terre... Mais comme les paléontologues, il nous faut distinguer les périodes d'évolution normale durant lesquelles les espèces apparaissent et disparaissent sans cesse sur des temps longs et les périodes de ruptures où les extinctions sont rapides et massives. La dernière extinction remonte à la fin du Crétacé, il y a 65 millions d'années. Elle serait due à un bouleversement majeur de l'écosystème terrestre et a entrainé notamment la disparition des dinosaures. Depuis, un nouvel équilibre s'est constitué, mais aujourd'hui, certains spécialistes l'estiment menacé...Quelles menaces nouvelles pèsent sur la biodiversité ?Montrant du doigt les activités humaines, certains spécialistes de la biodiversité n'hésitent pas à annoncer les prémices d'une nouvelle extinction. Toute espèce a une durée de vie limitée de l'ordre de 5 à 10 millions d'années. Or, le rythme actuel de disparition des espèces est très largement supérieur au rythme de disparition « naturel », estime le CNRS. Cette accélération du rythme des disparitions inquiète particulièrement car l'extinction d'espèces en entraîne d'autres, en cascade. Les causes principales de la perte de biodiversité sont majoritairement dues à l'activité humaine. Jugez plutôt la liste établie par le groupe de scientifiques du Millenium Ecosystem Assessment (2005) : la destruction ou la dégradation des écosystèmes et des habitats en raison de la déforestation, de l'urbanisation, de la fragmentation des habitats, etc. ; le changement climatique, du notamment aux rejets des gaz à effet de serre ; la surexploitation de la diversité via des activités de chasse, de pêche et d'exploitation forestière qui excèdent les capacités de régénération des espèces ; la prolifération d'espèces invasives, sur-cultivées, importées ou encore introduites accidentellement ; la pollution de l'air, de l'eau ou des sols. En outre, ces facteurs interagissent et tendent à se renforcer.Pourquoi vouloir préserver la biodiversité ?Certaines raisons relèvent de la morale ou de l'éthique. Le grand public y est souvent très sensible et se montre prêt à « reconnaître un droit de vie aux autres espèces, attribuer à cette biodiversité une valeur intrinsèque » ou à « léguer aux générations futures un monde dont la diversité biologique est intacte, au nom de la solidarité intergénérationnelle » comme le résume Aurélien Boutaud.Mais d'autres raisons, plus utilitaristes, sont utilisées notamment lorsque la biodiversité est considérée comme une richesse. Les services rendus par la biodiversité sont difficiles à chiffrer, mais leur disparition pourrait s'avérer catastrophique pour l'économie humaine. On peut citer par exemple les services rendus par les insectes pollinisateurs, indispensables dans de nombreuses cultures et estimés à plus de 150 milliards d'euros chaque année, les services rendus par les organismes contribuant au traitement et à la dépollution des écosystèmes, ou encore les services « culturels » (spirituels, esthétiques, récréatifs, etc.). La biodiversité constitue aussi une source potentielle d'informations et de connaissances. Entamer la biodiversité équivaut à brûler des bibliothèques entières d'informations, pour reprendre l'image du biologiste Edward O. Wilson (2007). Et plus grave, « nous n'avons aucune idée de la valeur pour l'humanité de ce que nous perdons en termes d'information » (E.O.Wilson). En d'autres termes, des molécules disparaissent alors qu'elles auraient pu avoir une grande utilité pour l'humanité et cette perte est irréversible.Le changement climatique est-il vraiment dû aux activités humaines ?    Le GIEC (Groupe d'Experts Intergouvernemental sur l'Evolution du Climat) affirme que l'évolution de la température terrestre au 20ème siècle est due aux émissions de gaz à effet de serre anthropiques, c'est-à-dire relevant des activités humaines. Pourtant, des experts sont encore sceptiques et jugent cette explication peut crédible...Le changement climatique n'est-il pas un phénomène naturel ?Bien-sûr et depuis 4 milliards d'années, le climat de la Terre évolue constamment. Les prélèvements de glace réalisés dans l'Antarctique le prouvent, au moins pour les 400.000 dernières années. L'ère quaternaire, période géologique débutant il y a environ 2 millions d'années et qui se poursuit encore actuellement, se caractérise par l'alternance environ tous les 100.000 ans de longues périodes glaciaires et de périodes de réchauffement plus courtes. Nous sommes actuellement dans une période interglaciaire avec une température plus élevée que la moyenne des 400.000 dernières années. Ce passage à une période interglaciaire s'explique par plusieurs facteurs naturels : la position de la Terre par rapport au soleil, les fluctuations de l'activité solaire, les modifications de la composition de l'atmosphère et l'effet de serre.Mais un net réchauffement est observé depuis le début du 20ème siècle, et plus encore depuis 1970...Si les experts ne s'entendent pas sur l'importance du phénomène et s'il y a eu ou non des précédents au cours de l'Histoire, tous s'accordent sur l'importante augmentation de température depuis le début du 20ème siècle et particulièrement entre 1970 et 2000. Ensuite, les avis divergent quant il s'agit d'expliquer cette augmentation de température. La grande majorité de la communauté scientifique impute le réchauffement actuel au renforcement de l'effet de serre, du fait de l'augmentation des concentrations de gaz à effet de serre dans l'atmosphère (vapeur d'eau, CO2, méthane...). Mais certains scientifiques pensent que les facteurs naturels, l'influence du soleil en particulier, jouent un rôle plus important et estiment que l'influence du CO2 a été surestimée dans les modèles utilisés.L'augmentation de l'effet de serre est majoritairement due à l'activité humaineCette explication est largement admise par la communauté scientifique et très documentée. Les émissions de CO2 ont augmenté de plus de 30% depuis la fin du 19ème siècle, le méthane de 150%. Cette augmentation s'explique par la combustion de carburants fossiles toujours plus grande, par la déforestation et certaines pratiques agricoles (bétail et rizicultures notamment).Un réchauffement climatique certain... mais aux explications encore incertainesEn bref, le réchauffement climatique ces dernières années est avéré et les modélisations pour l'avenir, bien qu'incertaines, sont alarmantes. Selon les scénarios, la température moyenne augmenterait de + 1,8 à + 4°C pour la fin du 21ème siècle, soit des niveaux jamais atteints dans l'histoire de l'humanité. Le réchauffement climatique s'explique par la hausse des concentrations des gaz à effet de serre dans l'atmosphère. Mais l'augmentation de l'effet de serre fait encore débat : est-elle due aux activités humaines du 20ème siècle induisant une plus forte production de gaz à effet de serre ? Ou bien, est-elle due au soleil, comme cela a été le cas précédemment au cours de l'ère quaternaire ? Quelle est la part de notre responsabilité ? Pouvons-nous agir et enrayer le phénomène ? Le sujet est encore loin d'être clos... Le développement durable et le principe de précaution sont-ils des freins au « progrès »?    Les enjeux du développement durable ont mis au jour notre pouvoir sur la nature (les activités humaines allant jusqu'à changer notre climat, éteindre des espèces, ou pour le moins y contribuant), mais aussi notre incapacité à mesurer précisément notre rôle dans ces phénomènes et à y apporter des solutions concrètes et efficaces. Dans ce contexte d'incertitude, le principe de précaution est né. Certains voient dans son application une menace pour le développement technologique. D'autres soulignent au contraire combien le principe de précaution constitue une opportunité d'améliorer la recherche et l'innovation.Naissance du principe de précautionPlus que la remise au goût du jour du bon sens, d'une certaine sagesse ou d'un appel à la prudence, le principe de précaution prend en compte le renversement du rapport de force entre l'Homme et la Nature. Le philosophe allemand Hans Jonas, un des principaux artisans du principe de précaution, constate que les progrès de la technique ont permis à l'Homme de développer une puissance sans précédent mais potentiellement menaçante pour la pérennité de la vie humaine sur Terre. Cette puissance inédite implique également une responsabilité nouvelle pour l'homme, notamment à l'égard des générations futures. Jonas appelle donc à une forme de maîtrise de la technique, conditionnée par un principe éthique visant à assurer « la permanence d'une vie authentiquement humaine sur Terre ». On parle alors de principe de prévoyance en Allemagne dans les années 1970. Ce principe, enrichi et précisé, sera à l'origine du principe de précaution introduit dans la Déclaration de Rio sur l'environnement et le développement (1992) : « pour protéger l'environnement, des mesures de précaution doivent être largement appliquées par les Etats selon leurs capacités. En cas de risque de dommages graves ou irréversibles, l'absence de certitude scientifique absolue ne doit pas servir de prétexte pour remettre à plus tard l'adoption de mesures effectives visant à prévenir la dégradation de l'environnement » (article 15). En France, la loi Barnier (1995) sur les espaces naturels intègre la notion de principe de précaution pour la 1ère fois.Précaution, prévention ou prudence ?Le principe de précaution s'applique dans un contexte marqué par un risque qui est à la fois incertain (le risque est supposé, mais pas démontré) et potentiellement grave et/ou irréversible. Cette dimension est bien souvent oubliée dans les médias et par le grand public : la précaution est relative à des risques potentiels (ex. les OGM, les ondes de téléphones portables, les nanotechnologies...) et la prévention à des risques avérés (ex. conduire en état d'ébriété, jouer à la roulette russe, s'exposer au virus de la grippe...). A titre d'illustration, c'est au nom du principe de précaution que l'utilisation de l'amiante aurait pu être évitée dès 1910, au moment où les risques liés à son usage ont commencé à être évoqués. A partir des années 1960, le risque de l'usage de l'amiante étant avéré, on se situe dans le champ de la prévention.La prudence, dans le sens où Kourilsky et Viney, cités par Aurélien Boutaud, l'envisagent, fait figure de dénominateur commun puisqu'elle implique de « réfléchir à la portée et aux conséquences de ses actes et prendre ses dispositions pour éviter de causer des dommages à autrui » (1999).Le principe de précaution s'oppose à une certaine vision du progrès...Si l'on considère le progrès comme une démarche totalement libre, sans aucune régulation, alors la principe de précaution peut être vu comme un obstacle. Mais si le progrès est envisagé comme un processus visant de nouvelles connaissances et une meilleure adéquation au monde dans lequel nous vivons, alors le principe de précaution est un remarquable allié. Car son application appelle à davantage de connaissances, même si pour certains, il pousse à « en faire trop » : les opposants exagèreraient les risques, les décideurs chercheraient à « se couvrir » au maximum, etc.Le principe de précaution invite à l'action dans un contexte d'incertitudesLe principe de précaution ne vise pas l'inaction ou l'abstention. Il s'agit bel et bien d'un principe d'action visant la prise de décisions dans un contexte d'incertitudes. Pour cela, différentes procédures sont développées afin d'améliorer la connaissance du risque, d'assurer l'existence et la transparence du débat public entre experts, décideurs et société civile et de prendre des mesures proportionnées et révisables en fonction de l'avancée des connaissances... L'application du principe de précaution est donc loin de s'opposer au changement ou au progrès.La croissance économique est-elle compatible avec la protection de l'environnement?    Pour certains, la croissance est incompatible avec la protection de l'environnement puisqu'elle nécessite de consommer des ressources finies. D'autres, au contraire, considèrent que la croissance est le meilleur moyen pour une société de protéger l'environnement. Comme le relate Aurélien Boutaud, la controverse est ancienne, perdure encore à l'heure actuelle et nous amène à réfléchir à la notion même de croissance.Dans les années 1970, la croissance est remise en cause pour des raisons écologiquesAu début du 19ème siècle déjà, des économistes évoquaient la perspective, inévitable à leurs yeux, d'un « état stationnaire », dû aux facteurs naturels qui limiteraient à terme la croissance économique. Certains y voient même l'aboutissement d'un long processus d'émancipation qui permettrait à l'homme de travailler moins et de profiter davantage des plaisirs immatériels.Les progrès technologiques ont ensuite contribué à donner l'illusion qu'il serait possible de s'affranchir des limites naturelles et de poursuivre sans limite la croissance. Mais dès la fin des années 1960, on observe la montée en puissance des préoccupations écologiques : dégrader l'environnement n'est pas sans danger pour l'homme. Le dogme dominant de la croissance est alors remis en cause par de nombreux intellectuels. Une croissance infinie est-elle possible dans un monde aux ressources finies ? La controverse éclate au grand jour au début des années 1970 avec la publication du rapport du Club de Rome sur les limites de la croissance. Ce rapport sera vivement critiqué mais son principal message marque les esprits : la recherche d'une croissance continue ne peut mener à terme qu'à l'épuisement de nos ressources et donc, à notre perte.La croissance améliore certains aspects de l'environnement « local » mais augmente les pressions sur les ressources « globales »Dans les années 1990, le bilan environnemental s'affine. Le Sommet de la Terre de Rio de Janeiro (1992) contribue à sa diffusion au sein du grand public : changement climatique, extinction de la biodiversité, désertification, épuisement des ressources fossiles et de certaines ressources renouvelables font désormais les gros titres des journaux. Les hypothèses sur les corrélations entre la croissance économique et les facteurs environnementaux se multiplient. Celles de l'économiste américain Simon Kuznets suggèrent que la dégradation de l'environnement n'est qu'une phase primaire du développement économique. Passé un certain stade, la pression sur l'environnement naturel serait obligatoirement amenée à diminuer, si bien qu'à terme la croissance économique pourrait être le meilleur allié de l'environnement.Mais il semble que les diminutions portent essentiellement sur des paramètres locaux. Par exemple, la part des surfaces d'aires naturelles protégées augmente généralement à partir d'un certain niveau de revenus et d'éducation, des réductions d'émissions de certains gaz polluants sont enregistrées dans les pays riches en raison de la mise en place de normes ou de la délocalisation des industries vers d'autres pays. Quant aux  impacts globaux (émissions de CO2, consommations d'énergie), ils restent étroitement corrélés au niveau de richesse puisque l'empreinte écologique d'une nation est proportionnelle à son PIB.Viser la stabilité, l'épanouissement des personnes et le respect des limites écologiques plutôt que la croissance ?Ces constats alarmants ont conduits plusieurs auteurs à questionner la notion de croissance : est-elle nécessaire et dans quelle mesure ? Passé un certain seuil de richesses, la croissance n'augmente plus le bien-être : pourquoi dans ce cas, continuer à la rechercher dans les pays riches ? Vers quels modèles économiques se tourner ?La décroissance est défendue par certains auteurs mais elle pourrait générer des instabilités profondes dans nos économies et nos sociétés, très attachées au travail, à la consommation, etc. Quant au découplage, c'est-à-dire le fait d'allier une croissance économique et la diminution de l'impact écologique, il implique pour les pays riches de diviser par 2 ou 3 leur empreinte écologique...Plusieurs auteurs proposent d'inventer une forme d'économie de prospérité post-croissance. Il s'agit de viser la stabilité et le bien-être et de rejeter le consumérisme en privilégiant l'épanouissement des personnes dans le respect des limites écologiques, l'investissement dans des actifs écologiques (investir pour absorber du carbone et non en expulser) et une politique de temps de travail adapté. Localement, des modèles de développement économique durable peuvent s'appliquer et faire système afin de passer d'une « économie de biens » à une « économie de liens ». L'alimentation biologique peut-elle contribuer au développement durable ?    L'alimentation représente environ 30% de l'empreinte écologique d'un Français (Hails, 2008). Les pratiques agricoles, les circuits de distribution, les emballages, les pollutions entrainées par certaines pratiques, etc. pèsent sur l'environnement. Si l'agriculture biologique apparaît souvent comme une alternative, elle reste encore minoritaire et son coût empêche de nombreux consommateurs d'en bénéficier.Le bio : plus cher et réservé aux « bobos » ?Les enquêtes réalisées en France sur le sujet montrent toutes que les produits alimentaires issus de l'agriculture biologique sont plus chers que ceux issus de l'agriculture intensive : de 50 à 70% en moyenne. Le profil type des consommateurs bio correspond à des personnes un peu plus aisées que la moyenne et plutôt issues des catégories socioprofessionnelles supérieures. Mais quelques nuances doivent être apportées.Si l'on s'intéresse aux non-consommateurs de bio, on s'aperçoit que les raisons financières n'expliquent pas tout. Des raisons socioculturelles expliquent aussi cette non-consommation : le poids des habitudes alimentaires tout d'abord, deux tiers des non consommateurs avouent ne pas avoir le réflexe d'acheter des produits bio, et le manque d'information ou d'intérêt ensuite (d'après l'Agence BIO).Il faut ensuite relativiser ces écarts de prix car les comparaisons sont parfois difficiles. Certes, le label Bio entraîne des surcoûts : la moindre productivité de l'agriculture biologique (plus d'emplois pour moins de volumes), mais aussi le coût de la période de conversion des terres (durant laquelle l'agriculture ne peut bénéficier du label) et les coûts liés à la certification et au contrôle. Soulignons aussi que le système de subventions de l'agriculture favorise les systèmes de culture à forte productivité, donc très peu d'exploitations pratiquant l'agriculture biologique. En revanche, l'agriculture intensive a de nombreux coûts cachés, car pris en charge par l'ensemble de la société : la dépollution de l'eau, des sols, le traitement des conséquences des pesticides sur la santé, etc. Le consommateur n'en a donc pas forcément conscience. Enfin, des observateurs ont dénoncé les pratiques des grands distributeurs profitant de l'engouement pour les produits bio pour augmenter leurs marges.Pourquoi manger bio ?Rappelons tout d'abord que « l'agriculture biologique se définit comme un mode de production agricole exempt de produits chimiques de synthèse et d'OGM. C'est aussi et surtout un mode de production durable et respectueux des hommes et de leur environnement. Pour cela, il s'appuie sur une approche globale de l'exploitation et de son milieu, aussi bien dans ses composantes technico-économiques que sociales, environnementales ou historiques. L'agriculture biologique est basée sur l'équilibre entre le sol, les animaux et les cultures ».Manger bio a effectivement un impact positif sur l'environnement à différents niveaux : protection de la biodiversité, respect des sols, protection des nappes phréatiques, etc. Il semble toutefois que manger bio n'ait pas une influence si forte sur notre empreinte carbone. Mieux vaut pour cela modifier le contenu de nos assiettes et nos habitudes de consommation...Pour réduire notre empreinte écologique, mangeons autrement !Ce message devient une évidence à la lecture de l'étude d'Aurélien Boutaud. Les consommations de viandes, de poissons, de produits laitiers et de produits transformés ont considérablement augmenté depuis les années 1950. Ces habitudes pèsent sur le budget des ménages et ont un impact très fort sur l'environnement. Par exemple, la production de viande contribue au réchauffement climatique via la conversion des forêts en terres agraires, la consommation de carburant par les machines agricoles, la fabrication et le transport des fertilisants, la production de gaz à effet de serre par les animaux, etc. Conserver ces mêmes habitudes alimentaires et passer au bio coûte effectivement plus cher. Mais en revanche, diminuer sa consommation de viande et de produits transformés préserve à la fois l'environnement et son porte-monnaie... ce qui facilite l'achat de produits bio.Un autre levier pour réduire l'empreinte carbone de l'alimentation consiste à consommer des produits locaux de saison et privilégier les circuits courts afin de réduire l'impact lié au déplacement : AMAP, marchés fermiers, points de vente collectifs ou coopératifs, épiceries solidaires. Il est souhaitable aussi de préférer les filières équitables pour les produits plus exotiques comme le café, le chocolat... Jusqu'à quel point la technique peut-elle nous aider ? L'exemple de la voiture électrique    Des nombreux espoirs sont portés dans l'innovation scientifique et technique. Beaucoup en sont convaincus : les sciences et techniques nous donneront des moyens de diminuer nos consommations d'énergie, nos émissions de gaz à effet de serre, d'économiser l'eau potable, de préserver la qualité des sols, etc. Mais la vraie question est de savoir si cela sera suffisant... ces solutions ayant elles-mêmes un impact sur l'environnement. L'exemple de la voiture électrique illustre bien la complexité de cette question.La technique, une alliée du développement durable... mais sous certains conditionsConsidérons les transports en voiture individuelle. Leur impact sur l'environnement dépend du nombre de personnes équipées, du volume de déplacements et du type de véhicules utilisés (puissance, mode de motorisation...). A population égale, réduire l'empreinte écologique des transports individuels est possible soit en réduisant les besoins de transport, soit en améliorant la performance énergétique et environnementale des véhicules. Cette alternative est la promesse des « véhicules propres », comme les véhicules utilisant l'électricité comme carburant.Quel bilan énergétique peut-on dresser pour ces véhicules électriques (B. Dessus, 2009) ? Il est très favorable pour ce qui concerne la chaîne traction, c'est-à-dire la consommation d'énergie du « moteur à la roue ». Le rendement d'un moteur électrique (supérieur à 90%) est supérieure à celui d'un moteur thermique (environ 40%). Mais le bilan est nettement moins bon « en amont du moteur », c'est-à-dire lorsque l'on considère toute la chaîne de production, de transport et de stockage de l'électricité. Et les rendements varient aussi selon les filières de production de l'électricité... Au final, le bilan énergétique d'un moteur électrique est au pire équivalent au moteur classique (lorsque l'électricité est produite par la filière nucléaire), et au mieux deux fois meilleur (lorsque l'électricité est produite avec par la filière gaz naturel).Quant au bilan des émissions de CO2, il dépend en grande partie du mode de production de l'électricité. Privilégier l'énergie nucléaire pour produire l'électricité alimentant les véhicules électriques aura un impact très favorable en matière d'émissions de CO2 mais le bilan énergétique sera peu satisfaisant en raison du rendement assez faible des centrales nucléaires. Quant à la production d'électricité à partir de gaz naturel, son bilan énergétique est plus favorable mais le bilan en émissions de CO2 est moins intéressant. Cette alternative est néanmoins recommandée par certains experts à moyen terme.Enfin, fait non négligeable, avant même d'avoir été utilisée, une voiture -quelque soit son mode de motorisation- nécessite une grande quantité d'énergie. Notons donc que la prise en compte du bilan énergétique de la conception et la fabrication d'une voiture peut changer le bilan de manière significative.Pour l'instant, un bilan écologique en demi-teinte pour la voiture électrique... mais demain?La voiture électrique améliorait considérablement son bilan écologique si l'électricité serait produite à partir d'énergies renouvelables. Celles-ci sont en augmentation au sein de l'Union Européenne depuis vingt ans mais comme les consommations totales d'énergie augmentent aussi, les énergies renouvelables représentent toujours sensiblement la même proportion.En d'autres termes, les véhicules électriques permettent d'espérer une amélioration globale des performances énergétiques du parc automobile français de 30 à 40% au mieux à l'horizon 2050. Rappelons que dans le même temps, il convient de diviser par 4 les émissions de gaz à effet de serre pour respecter les  engagements nationaux et internationaux. Les gains obtenus par l'utilisation hypothétique de « véhicules propres » ne seront probablement pas suffisants (A.Boutaud, 2011). En outre, notre comportement de mobilité  évoluera peut-être : serons-nous plus ou moins nombreux à utiliser une voiture et à quelle fréquence ?Allier les progrès de la technique et des changements de comportements et de modes d'organisationDepuis toujours, des gains écologiques obtenus grâce à des améliorations techniques de la production de bien ou de service peuvent être annulés par la simple augmentation de la consommation de ce bien ou de ce service. C'est ce que l'on appelle l'effet rebond. Par exemple, les gains réalisés en matière de rendement énergétique des moteurs à combustion depuis 1990 ont été largement « annulés » par l'alourdissement des véhicules, leur niveau d'équipement (comme la climatisation) et surtout, l'accroissement du nombre de kilomètres parcourus. Ces effets sont évidemment renforcés si le nombre de véhicules augmente... Et une augmentation de +400% de véhicules au niveau mondial à l'horizon 2050 est prévus par le Fond Monétaire International.Les progrès de la technique ne pourront donc à eux seuls compenser ces prévisions, réduire l'empreinte écologique des véhicules individuels, et encore moins résoudre les problèmes d'embouteillages, de bruits, de gestion des déchets générés, etc. (JM. Jancovici). En bref, les changements de comportements et de modes de vie sont indispensables pour inverser réellement la tendance et alléger le poids de la mobilité sur l'environnement. Il s'agit par exemple d'adopter des véhicules beaucoup plus légers, moins puissants, peu gourmands en énergie, d'opter pour des modes de déplacements doux ou des transports en commun, etc. La dimension sociale du développement durable est-elle (trop souvent) oubliée ?    Le but du développement durable est aussi de favoriser « un état d'harmonie entre les êtres humains et entre l'homme et la nature » (Commission mondiale sur l'environnement et le développement). En d'autres termes, il s'agit « d'un développement qui économise la nature sans nuire à la cohésion sociale ou, dans un autre sens, un développement qui respecte l'homme tout en ne sacrifiant pas son environnement » comme l'explique l'économiste Sandrine Rousseau, cité par Aurélien Boutaud. Pourtant et depuis l'origine du concept de développement durable, les débats se concentrent sur les dimensions environnementale et économique. Qu'en est-il de la dimension sociale ? Pourquoi l'avenir de la planète semble-t-il mettre l'avenir de l'humanité au second plan ?La question sociale est intimement liée aux enjeux économiques et écologiquesL'évolution de la répartition des richesses prouve bien ces liens. A l'échelle mondiale, le niveau de développement moyen a augmenté et la pauvreté a reculé, mais les inégalités économiques se sont également accrues (S.Brunel, 2005)... car les riches se sont enrichis plus vite que les pauvres.Les pays à hauts revenus, représentant seulement 15% de la population mondiale, sont responsables de 78% de l'empreinte carbone mondiale (Global Footprint Network, 2010). Pourtant, ce sont les pays pauvres qui subiront le plus intensément les effets de la dégradation des écosystèmes, car ils tirent l'essentiel de leurs moyens de subsistance de la nature. Ils seront aussi les premières victimes du changement climatique : d'ores et déjà, entre 2000 et 2004, 98% des victimes de catastrophes climatiques habitaient des pays en développement d'après les Nations-Unies.Enfin, il faut aussi considérer l'échelle infranationale où les inégalités écologiques sont fortes. Elles peuvent toucher la qualité du cadre de vie, l'exposition aux risques et aux nuisances... Plusieurs observateurs ont montré que l'injustice sociale et l'injustice environnementale se superposent sur les territoires (J.Theys, 2002) . Ces inégalités s'accompagnent souvent d'une dépendance plus grande aux énergies fossiles, pour les déplacements et le chauffage notamment. Les classes moyennes et modestes vivant dans les communes périurbaines et rurales subiront de plein fouet les variations de coût des énergies.La dimension sociale du développement durable est centrée sur les questions de solidaritésSolidarités s'écrit au pluriel car il s'agit bien de considérer la solidarité entre individus, entre nations et entre générations. Ces 3 déclinaisons sont présentes dans les textes officiels.La solidarité intergénérationnelle suscite des controverses cependant. On distingue deux mouvements s'opposant sur l'importance relative à accorder à l'économie et à l'environnement et sur la question du legs intergénérationnel. Pour les partisans de la durabilité faible, l'économie reste prépondérante. La nature peut être considérée comme un capital substituable par d'autres formes de capitaux ou d'actifs « artificiels » (financiers, techniques, humains, etc.). La dégradation de la nature n'est donc pas considérée comme une limite absolue à la durabilité car d'autres capitaux « artificiels » peuvent résoudre les problèmes posés. Par exemple, les cultures d'OGM viendront aisément remplacer les cultures naturelles. L'important est donc de léguer aux générations futures une somme équivalente de capital « total ». Pour les partisans de la durabilité forte, l'environnement est prépondérant. Les ressources naturelles ne sont pas inépuisables, ni extensibles. Les générations actuelles ont donc le devoir de léguer aux générations futures l'environnement dans un état au moins égal à celui dont elles ont hérité.Quant à la solidarité entre individus, elle fait également débat. Pour les uns, la décroissance économique ne peut être envisagée et figerait les inégalités actuelles. Seule la croissance économique permettra la création d'emplois, la redistribution des richesses et donc la lutte contre la pauvreté. En d'autres termes, il faut « agrandir le gâteau pour que chacun puisse y trouver une part » (A.Boutaud, 2011). La croissance nécessaire viendra de la technologie qui permettra d'augmenter le productivité malgré la raréfaction des ressources et de maintenir les emplois nécessaires. Pour les autres, au contraire, il est impératif de « consommer moins et répartir mieux » comme le résume Paul Ariès, partisan de la décroissance. Considérer la dimension sociale du développement durable implique non pas « d'augmenter le gâteau », mais de le partager plus équitablement : décroissance des plus riches, revenu maximum admissible, revenu social garanti pour tous les citoyens, etc. La solution technologique n'a pas de place dans ce raisonnement.Reconsidérer le capital humain ?Au-delà des questions d'inégalités et de solidarités, le développement durable appelle à questionner la définition même du développement et de toutes ces composantes. L'épanouissement humain en fait partie. C'est ainsi que des indicateurs de bien-être ont vu le jour aux côtés des indicateurs de croissance économique et ont permis d'apprécier une vision qualitative du développement. L'Indice de Développement Humain (IDH) créé en 1990 inclue la notion de « capabilités » c'est-à-dire l'importance d'offrir aux individus une capacité d'émancipation nécessaire pour ouvrir les possibilités de leur épanouissement, les moyens matériels et immatériels, comme l'accès à la santé, à l'éducation, etc. La prise en compte des aspects immatériels du développement humain n'est pas neutre. Il apparaît que certaines régions du monde  parviennent à un niveau de développement humain élevé malgré un niveau de vie matériel, et donc une empreinte écologique, très modestes. L'exemple de l'Etat du Kérala en Inde (30 millions d'habitants) le prouve : des faibles revenus (350 dollars/an/habitant) mais une espérance de vie proche de 75 ans, un niveau d'alphabétisation très important et un taux de scolarisation avoisinant les 100%.Miser sur l'innovation sociale ?C'est le pari des pays du Nord de l'Europe et force est de constater qu'ils font partie des rares pays à être parvenus à stabiliser, puis à réduire, leur empreinte écologique sans pour autant entamer leur niveau de développement humain. Comment ? Via des dynamiques d'innovation sociale. Cette formule désigne le plus souvent des solutions inventées par ces citoyens, des utilisateurs de services ou des habitants pour répondre à une demande en relation avec les enjeux sociaux et écologiques du développement durable. Citons par exemple : l'habitat coopératif, les AMAPS (associations pour le maintien de l'agriculture paysanne), les recycleries ou ressourceries, les jardins partagés, etc.Ces pratiques sont de plus en plus souvent intégrées dans les stratégies locales de développement durable (comme les Agendas 21 locaux). Mais la question sociale reste encore peu abordée dans les politiques de développement durable « peut-être parce que, au lieu de cantonner les débats à des enjeux de spécialistes l'enjeu social pose inévitablement la question plus politique : quelle société voulons-nous, pour nous et pour les générations futures ? » avance Aurélien Boutaud.L'aménagement du territoire doit-il être plus dense pour être durable ?     Faudra-t-il oublier à jamais les maisons individuelles ? La question est posée car l'étalement urbain et ses impacts sur l'environnement sont considérables. Pourtant, la densification n'apparait pas comme une réponse indiscutable et suffisante pour nombre d'observateurs...L'étalement urbain a un coût écologique particulièrement lourdL'étalement urbain se caractérise d'abord par sa très forte emprise au sol. Les surfaces artificialisées, c'est-à-dire ayant perdu les qualités d'un milieu naturel, ont augmenté de 42% entre 1982 et 2003 (bien plus que la population française qui n'a augmenté que de 10% environ) d'après le Commissariat général au développement durable. Cette augmentation s'est faite au détriment majoritairement des espaces agricoles périurbains et des milieux semi-naturels dont l'artificialisation accroît la fragmentation des écosystèmes.En outre, les habitats individuels concernés sont des grands consommateurs d'énergie et d'eau. Leurs habitants sont aussi fortement dépendants de leurs voitures individuelles. Les études montrent clairement que les taux de motorisation sont beaucoup plus élevés en périphérie qu'en centre-ville, en raison de l'éloignement des principaux services et du coût plus élevé des transports en commun dans les territoires périurbains. Par conséquent, on constate une forte corrélation entre le niveau de densité urbaine et la quantité d'énergie consommée pour les déplacements, et donc les émissions de gaz à effet de serre.Enfin, il faut souligner aussi l'impact paysager de l'étalement urbain. Des photos comparatives, prises à seulement 30 ou 40 ans d'intervalle, le démontrent plus qu'un long discours.La densification est-elle une réponse suffisante ?Densifier apparait donc comme une solution évidente : cela permet d'épargner les surfaces agricoles, de réduire les déplacements individuels, de limiter les consommations d'énergie des habitats, etc. Mais les villes denses doivent faire face à d'autres problèmes. Elles sont plus vulnérables aux vagues de chaleur (souvenons-nous de la canicule de 2003) et elles concentrent certaines nuisances comme le bruit, la pollution atmosphérique, le trafic routier... qui participent à la dégradation du cadre de vie. Si les villes denses réduisent les consommations d'énergie liées aux transports domicile-travail, leurs habitants les fuient dès que possible pour retrouver un peu de nature pendant les week-ends et les vacances... contrairement aux périurbains qui profitent de leur lieu de vie. En considérant les transports sur l'année, le bilan pourrait bien s'équilibrer, voire s'inverser...Que peut-on faire de plus ?Aurélien Boutaud recense une certain nombre de mesures qualitatives pour que la densité soit effectivement un élément de durabilité. Tendre vers davantage de mixité fonctionnelle permettrait de limiter nombre de déplacements et donc la place de la voiture en ville. Cela implique de privilégier le mélange des fonctions au sein d'un même territoire, rapprocher et mélanger les lieux de vie, de travail, de commerce et de loisirs, et donc rompre avec certaines logiques de l'urbanisme misant sur la spécialisation des territoires (zones commerciales, zones résidentielles, etc.). Cette mixité fonctionnelle, économisant des déplacements, libèrerait des espaces pour introduire de la nature en ville (parcs urbains, îlots de fraicheur...).Densité et mixité des fonctions doivent aussi s'accompagner d'efforts sur la qualité environnementale et architecturale du bâti, avec en particulier la réhabilitation du parc existant dans le respect des normes.Les éco-quartiers (comme le quartier Vauban à Fribourg) cumule ces différentes caractéristiques avec succès. Mais comment passer à l'échelle d'une métropole ? Une métropole multipolaire ou polynucléaire est proposée par le courant du « nouvel urbanisme ». Il s'agit d'une métropole composée de pôles urbains denses et à forte mixité fonctionnelle, inter-reliées par des infrastructures de transports publics efficaces.En bref, la densité urbaine représente un élément de réponse pour tendre vers un développement durable mais il doit s'accompagner d'autres mesures qui impliquent véritablement un nouveau rapport à la ville.Sommes-nous trop nombreux sur Terre ?    Près de 7 milliards d'êtres humains sur Terre, est-ce trop ? Si la croissance de la population mondiale est évidemment une composante de notre empreinte écologique, elle n'est pas la seule. Les modes de vie sont à considérer avec la plus grande attention quant il s'agit d'évaluer notre impact sur l'environnement.La croissance de la population mondiale, un facteur majeur de notre empreinte écologique ?Depuis le 19e siècle, on enregistre une augmentation sans précédent de la population mondiale. De 1960 aux années 2000, la population mondiale a doublé. Dans le même temps, l'empreinte écologique de l'humanité a été multiplié par 3 environ. Cette augmentation s'explique bien sûr par l'augmentation de la population mondiale, mais aussi par une hausse des niveaux de vie et de consommation, en particulier une augmentation importante des consommations d'énergie fossile.Qu'en sera-t-il demain ? Les scénarios de croissance démographique prévoient une stabilisation  de la population mondiale dans les décennies à venir. Nous serions dans une phase de transition démographique, liée à une évolution des comportements et une maîtrise de la natalité. Avec la baisse des taux de fécondité jusqu'à atteindre des niveaux proches de l'équilibre démographique (2 enfants par femme), la population mondiale se stabiliserait peu à peu. Cette transition devrait être achevée partout d'ici à 2050 selon les projections des Nations-Unies : la population mondiale s'élèvera alors à 9 milliards d'habitants environ. La planète sera-t-elle vivable ? Pour tenter de répondre à cette question, l'examen des autres facteurs déterminant l'empreinte écologique est nécessaire.Nourrir 9 milliards d'individus à l'horizon 2050 est-il possible ?Il est vraisemblablement possible d'améliorer les techniques de production agricole, mais il reste à savoir si cela est compatible avec une gestion des ressources à long terme. Intensifier la production agricole se traduit par des consommations importantes d'énergies fossiles et une dégradation de la qualité des sols.Autre possibilité : consommer autrement ! Il faut savoir qu'à production végétale égale, une augmentation de la consommation de viande réduit la part totale de calories disponibles pour l'homme. Car pour produire une calorie animale, il faut produire en amont environ 10 calories végétales pour nourrir cet animal. En d'autres termes, diminuer notre consommation de viande peut permettre de nourrir davantage de personnes, comme l'explique Hervé le Bras cité par Aurélien Boutaud.Les modes de vie des individus sont des facteurs plus importants que leur nombreSupposant que la population mondiale se stabilise aux alentours de 9 milliards, il semble possible de nourrir convenablement cette population grâce à l'amélioration de la productivité agricole et à l'évolution des modes de consommation. Comme le résume l'Institut National d'Etudes Démographiques (2008), « les êtres humains sont en voie de maîtriser la croissance de leur population. Mais pour vivre convenablement à 9 milliards, ils doivent apprendre à mieux gérer les ressources de la planète et à les partager de façon plus équitable. A  long terme, la survie de l'espèce humaine dépend tout autant sinon plus de la façon dont les hommes vivront que de leur nombre ».   