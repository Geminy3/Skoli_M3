Le robot iCub capable de coopérere avec l'Homme
Interview réalisée par Geoffroy Bing, le 23 novembre 2010Peter Ford Dominey, directeur de recherche en neurosciences et robotique (ICSC-CNRS) nous expose les recherches en cours, au sein de l’Institut Cellules Souches et Cerveau de l’INSERM de Bron,  sur le robot iCub. Le laboratoire lyonnais a en effet été sélectionné dans le cadre du programme européen Robotcub (6 M€ sur 5 ans) pour étudier le fonctionnement de notre cerveau. Les recherches en cours laissent entrevoir le chemin semé d’embûches vers le robot de demain, un robot capable d’apprendre et de coopérer avec l’homme.

Pour vous qu’est-ce qu’un robot ?Un robot, c’est un ordinateur incarné dans un corps mécatronique, qui peut ressembler au corps humain mais pas nécessairement, et qui est capable d’interagir avec son environnement. Vos recherches prennent appui sur les fertilisations croisées entre les sciences du développement cognitif et la robotique. Qu’est-ce que la robotique apporte aux sciences cognitives ?Notre robot est avant tout un outil de recherche au service des sciences cognitives. La méthode scientifique s’appuie sur l’élaboration d’hypothèses (par exemple, sur le rôle du regard dans la communication humaine). Nous traduisons ensuite ces hypothèses dans un programme robotique. Le robot devient, comme dans toute démarche scientifique, un modèle qui va  nous permettre de tester nos hypothèses. Dans nos recherches sur les interactions homme-homme par exemple, nous substituons une personne par le robot pour faire des tests. Dans les neurosciences, il nous permet aussi de comprendre comment perception, action et langage s’articulent dans le cerveau humain. Dans l’autre sens, qu’est-ce que les neurosciences peuvent apporter à la robotique ?Si nos hypothèses sont concluantes, nous allons pouvoir humaniser davantage le robot. Nous allons en effet pouvoir améliorer le traitement et la gestion du regard du robot, de sorte que celui-ci se rapproche davantage du regard humain par exemple. Les humains vont être plus à l’aise devant un tel robot. Est-ce à dire qu’un ordinateur ne suffit pas à modéliser notre cerveau, comme semble le soutenir un courant des sciences cognitives ? Il y a en effet deux approches des sciences cognitives. L’approche traditionnelle de l’Intelligence Artificielle d’une part, selon laquelle le cerveau fonctionne comme un ordinateur, manipule des symboles, fonctionne par la logique. D’autre part, il y a l’approche dont se réclame mon laboratoire, et qui est beaucoup plus fixée sur l’idée que finalement, le sens n’est pas désincarné, qu’il n’est pas que symbolique mais ancré dans l’interaction physique qu’un être a avec d’autres, ou avec son environnement. Quels sont les écueils technologiques et scientifiques auxquels vous vous heurtez aujourd’hui ?La partie sensori-motrice est un défi majeur. La préhension d’un objet par une main articulée est quelque chose d’extrêmement complexe et long à mettre au point. Nous nous attachons également à la dimension coopérative du robot. Faire en sorte que le robot soit capable de coopérer avec l’homme est très complexe également. Cela implique l’anticipation, la compréhension des objectifs de la personne avec laquelle le robot coopère. L’apprentissage du robot fait appel à des capacités multiples de perception, mémorisation, représentation dans l’espace et de motorisation. C’est une chaîne très complexe. Est-ce que vous préparez la prochaine génération de robots ?Oui, à notre manière, nous contribuons aux avancées qui visent à rendre le robot capable de s’intégrer et d’apprendre dans un environnement inconnu, de se familiariser avec les objets constitutifs de cet environnement, de les manipuler, et de prendre les bonnes décisions. Cela nécessite des algorithmes permettant de faire raisonner le robot dans un contexte qui ne lui délivre pas toute l’information dont il a besoin. Pour aller plus loin, on cherche à créer des robots capables de corriger leurs propres erreurs programmatiques  (comme lorsque un homme a accidentellement un accident vasculaire qui se résorbe au bout de quelques jours). Nous sommes à l’opposé des robots industriels ou des robots en expédition sur la lune, qui doivent faire rien de plus et précisément ce qu’ils étaient programmés à faire, au millimètre. La dernière chose que l’ingénieur souhaite de ces robots là, c’est qu’ils prennent des initiatives ! Quelle place dans la société, un robot comme iCub pourra-t-il avoir demain ?Les Japonais sont déjà friands des robots compagnons, des robots « aide scolaire » ou des assistants dans les cours d’école (pour compter les élèves notamment). Les recherches permettent également d’envisager des robots aides-soignants ou des robots orthophonistes. Le robot peut en effet reproduire, de façon simplifiée, l’interaction entre un patient et l’orthophoniste. Dans le domaine de la rééducation en général, il y a des débouchés probables, car la reproduction d’un geste répétitif est facile pour un robot. Des équipes japonaises ont montré par ailleurs que l’interaction d’un autiste avec le robot est plus facile qu’avec un humain parce que le robot, contrairement à l’humain, présente une régularité dans ses comportements qui sont plus facilement interprétables par les enfants autistes. Qu’est-ce qui a rendu l’équipe de recherche lyonnaise éligible au projet iCub selon vous ?Le comité de sélection iCub a réparti les axes de recherche entre 6 laboratoires au début. Notre compétence autour de l’interaction par la parole, de la reconnaissance des actions par la vision, et de la coopération a été reconnue.  L’Europe est très investie dans les programmes de recherche « neurosciences-robotique », c’est un signe. Je la remercie d’ailleurs pour les financements apportés. Je pense que le programme iCub participe d’une stratégie astucieuse de plateforme commune à l’ensemble  des laboratoires de recherche travaillant sur le même robot pour démultiplier les efforts de recherche et être compétitif par rapport au Japon. L’objectif, d’ici 4 ans, est de mettre tous nos travaux en commun et de faire un iCub tirant le meilleur de chaque laboratoire partenaire. Comment voyez-vous Lyon dans sa contribution à la compétitivité européenne de la robotique ?Mon laboratoire n’est pas très en prise avec d’autres acteurs lyonnais qui pourraient contribuer à la valorisation de la robotique. Je pense notamment à l’expertise lyonnaise en informatique et en jeux vidéos, qui pourraient assez facilement être réorientée pour faire des outils robotiques. Par exemple, les chercheurs et les entreprises de jeux vidéos sont compétents pour créer des représentations en 3D permettant au robot de mieux naviguer dans son environnement. Nous travaillons avec le Gipsa-lab (Grenoble Images Parole Signal Automatique) et avec le LAAS de Toulouse. Il apparait que notre réseau de collaboration est plus européen que régional.  