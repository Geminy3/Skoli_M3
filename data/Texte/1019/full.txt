Services urbains : Open data et modernisation des collectivités
Charles Nepote est chef de projet « partage des données publiques » à la FING.

On observe une accélération du mouvement open data depuis deux ans, avec une sorte de « course à l’échalote » que se livrent les collectivités publiques. Quelle est, selon vous, la part des obligations réglementaires et celle des motivations d’image, de transparence ou de développement économique qui entrent en compte dans cette accélération ?Je ne crois pas qu’on puisse parler de « course à l’échalote ». Sauf peut-être quand certaines collectivités publiques jouent clairement sur des dimensions de communication et d’effets d’annonce. Mais il me semble que la plupart des collectivités qui se sont lancées dans l’open data, comme Montpellier, Rennes, Nantes, Paris, etc. se sont vraiment préoccupées de ce que les gens allaient en faire. Elles ont eu le souci d’animer une dynamique autour des données ouvertes, de comprendre comment et pourquoi les gens allaient les utiliser. Pour moi, il y a eu un vrai travail de terrain, honnête, même s’il partait un peu dans tous les sens et qu’il y a eu des résultats plus ou moins bons. Les collectivités se sont lancées sans trop d’idées préconçues ; plusieurs d’entre elles ont d’ailleurs parlé d’expérimentations comme la CUB, Communauté urbaine de Bordeaux, qui s’était engagée sur un an, pour voir.Pour ce qui est des motivations, des collectivités ont constaté que leurs services passaient un peu de temps à répondre à des demandes ponctuelles d’accès à certaines données ; en publiant les données, elles ont souhaité gagner du temps.La législation est en effet du côté du public. En France, la création d’un droit opposable à la réutilisation des données a créé de fait une situation où l’acteur public se doit de rendre ces données réutilisables. Le droit ne dit évidemment pas qu’il est obligé de faire des portails, de donner ces données gratuitement ou à l’inverse de percevoir une redevance. Conscientes que juridiquement, elles devraient rendre les données réutilisables, des collectivités ont préféré prendre les devants en optant pour une expérimentation open data. Mais cet argument juridique n’est pas le principal. L’argument de la transparence a été très mis en avant par certains acteurs comme le Département de la Saône-et-Loire. Vient ensuite l’argument du développement économique qui a été, je pense, employé un peu à tort et à travers par les acteurs. Certains ont dit texto : « on va créer des emplois ». Pour moi, ce n’est pas du tout évident. De plus, ce ne sont pas des emplois qui sont faciles à mesurer. Certaines petites start up profitent de l’open data mais n’en font pas leur unique carburant. On parle beaucoup d’open data, mais concrètement a-t-on vraiment recensé toutes les données produites (ou à produire) par les collectivités publiques ?Au début, je croyais naïvement qu’on arriverait en quelques mois à lister les grandes catégories de données disponibles dans une ville, une agglomération, un département, etc. Mais en réalité, c’est très compliqué. D’abord parce que les acteurs eux mêmes ne savent pas ce qu’ils ont. La CUB, Communauté urbaine de Bordeaux, travaille à un recensement de ses données depuis plus deux ans et ne semble pas y parvenir. Le repérage des bases de données est très long. Il y a aussi une raison structurelle : bizarrement, on ne retrouve pas les mêmes données d’un acteur public à l’autre ; elles ne sont jamais faites tout à fait de la même manière. Par exemple, les inventaires du patrimoine – qui constituent une donnée à peu près partagée par beaucoup d’organismes publics - n’ont pas les mêmes normes de collecte de données, ou recouvrent des champs qui ne sont jamais complètement similaires.Les budgets des collectivités locales sont eux aussi impossibles à comparer. En fonction des habitudes des collectivités, les postes auxquels sont affectés un certain nombre de dépenses sont complètement différents, avec des noms, et des systèmes d’affectation, eux aussi, différents.Du coup ce grand recensement de données n’a pas été fait. Ce qui va probablement plutôt se passer, c’est une espèce d’harmonisation entre différentes collectivités pour arriver à des normes communes. De même, a-t’on mesuré l’utilité de ces données ?Il est aujourd’hui assez compliqué de dire que telle donnée est utile, et telle autre pas. On sent bien qu’il y a des jeux de données qui sont appréciés du public, pour lesquels il y a beaucoup de consultations et d’usages.On ne sait pas toujours à l’avance ce qui va être utile ou pas. On voit qu’il y a des jeux de données qui trouvent leur utilité très rapidement : sur les transports, ou, de façon plus anecdotique sur les prénoms : les livres sur la cote des prénoms ne donnent pas la cote par commune. Il y en a d’autres pour lesquelles c’est plus difficile à apprécier. On pense que ça ne va intéresser personne, on l’a publié parce que c’était facile et puis tout à coup, Ô ! Miracle ! On ne sait pas pourquoi, il trouve son usage et des croisements intéressants.  Le coût de production des données est-il un paramètre qui rentre en compte ?Il me semble que l’erreur pour les acteurs publics serait de considérer qu’ils ont une mission de produire spontanément de la donnée dont eux ne se serviraient pas forcément mais qui rendrait service à la population.Il faut un arbitrage politique à cette question ; c’est à l’acteur public de dire : oui cet investissement est intéressant pour moi parce que ça va me permettre de mieux gérer la collectivité, de rendre un service meilleur, ou bien non c’est effectivement trop cher, donc je ne vais pas produire cette donnée-là. Les données qui sont aujourd’hui produites pour les acteurs publics sont a priori utilisées. Leur coût de diffusion étant marginal, on estime que ces données doivent être gratuites à partir du moment où elles sont déjà produites pour les besoins propres de la collectivité. Après, se pose la question des données qui coûtent très cher à produire. Deux options se présentent : si l’acteur public en a besoin quoi qu’il arrive, on peut, dans ce cas, se poser la question de leur gratuité ou de leur valorisation financière. Enfin, troisième cas : les données dont l’acteur public n’a pas forcément besoin mais pour lesquelles il sent une appétence. Il peut décider de produire ces données, mais il risque alors de les produire pour quelques acteurs seulement, avec un coût important, au détriment du reste de la collectivité. Cela devient un peu problématique. La réutilisation des données pose un problème de droit, car la collectivité n’en a pas forcément la propriété. Ce sont parfois des opérateurs privés, dans le cadre de délégations de service public, qui sont propriétaires des données. Comment contourner cet obstacle ?Cette question de la propriété des données avance beaucoup. En région PACA ils ont rédigé des clauses dans les contrats de délégation de service public, ces clauses sont optionnelles pour l’instant, mais elles sont largement diffusées et la Région conseille à chaque nouveau marché de les employer. Ces clauses ont été diffusées au sein d’opendatafrance.net, un groupement informel d’acteurs publics français qui ont ouvert leurs données.La plupart des délégataires de services que j’ai rencontrés ou les cas que je connais ont plutôt bien joué le jeu : Suez environnement avec la CUB de Bordeaux, Kéolis avec Rennes, également la SNCF qui ouvre les données du Francilien, bientôt peut-être les données du TER en PACA. La négociation avec le délégataire semble plutôt encourageante. Je pense qu’en montant en compétence sur la question des données, petit à petit les services publics vont intégrer ces clauses un peu systématiquement dans leurs contrats de délégation. L’un des enjeux de l’open data est la transformation des données, leur traitement en systèmes d’information. La masse de données s’accroît tellement – on parle de big data – qu’il devient encore plus complexe de leur agréger en système d’information. Quelles sont les avancées sur ce point ; où en est la recherche ?Il y a effectivement l’angle de la masse avec le big data : comment exploiter des masses toujours plus importantes de données, comment arriver à les croiser ? Aujourd’hui, beaucoup de choses sont dites sur le big data, c’est un terme un peu fourre tout, un peu comme le cloud. Nous n’utilisons pas beaucoup ce terme là. Incontestablement, nous n’avons jamais eu accès aussi facilement à d’aussi grands volumes de données. Ils posent donc des problèmes de traitement, et des opportunités d’analyse comme jamais ! On en est aux balbutiements. En France, on a de très bons labos qui savent faire de très bons algorithmes pour extraire de la donnée, la rendre intelligible, la croiser, etc. On a de bonnes compétences industrielles dans ce domaine-là.Mais il y a aussi l’aspect organisation, normalisation et interconnexion des données. C’est le sujet du web sémantique qu’on appelle maintenant « web des données ». Ce web sémantique, centré sur les données plus que sur les documents permet des croisements de données très féconds, une très grande interopérabilité des données et une très grande facilité de requêtage de ces données. Il permet donc de construire des applications sur les données de façon beaucoup plus simple qu’auparavant. Surtout, il permet de rendre les données comparables. Cela donne de la valeur aux données et cela ouvre sur des usages plus riches, et plus rapidement. On a parfois le sentiment qu’on navigue un peu à vue. Les premiers retours de l’open data n’ont pas toujours été très probants. Y'a-t’il vraiment un marché économique autour des données ?Est-ce qu’il y a un marché des données ? C’est sûr que oui. Le Groupement Français des Industries de l’Information (GFII) pèse plusieurs milliards d’euros de chiffre d’affaires. Des structures comme NexisLexis, des grosses sociétés qui vendent des données - juridiques, comptables, etc. - représentent un marché très ancien, qui a déjà plusieurs dizaines d’années, qui existe réellement.Le GFII est très intéressé par l’open data mais finalement, pas tellement par la gratuité. Ce qui les intéresse davantage, c’est d’avoir des données de bonne qualité, et un service fiable. Certains industriels ne souhaitent d'ailleurs pas que la donnée soit gratuite parce que c’est une manière pour eux de verrouiller le marché. Ce n’est pas forcément dans l’intérêt de certains industriels d’avoir des marchés trop ouverts. Le marché de la data existe bel et bien, mais ce n’est pas sûr que ce soit le cas pour le marché de l’open data.Dans les pays anglo-saxons, on voit des applis qui ont un vrai modèle économique ; elles reposent en partie sur l’open data, mais aussi sur d’autres données. C’est le cas, par exemple, du service www.where-can-i-live.com. Ce service est très intéressant : vous indiquez la station de métro la plus proche d’où vous voulez habiter, le temps maximum de transport que vous êtes prêts à faire, en vélo, transport en commun, etc. Ensuite, vous indiquez des critères de prix, de nombre de chambres, etc. et l’appli affiche par des petits points les endroits où vous pourriez habiter à Londres. Et quand vous cliquez sur l’un de ces points, elle vous met en rapport avec des annonces immobilières. Le site fait appel à des données publiques (pour calculer les temps de transport, des prix moyens par quartier, etc.). Mais c’est un service enrichi, sous la forme de partenariats, par plusieurs sources de données notamment issues de vendeurs immobiliers. Je ne suis pas sûr qu’il y ait un marché strict de l’open data. A quelles conditions est-il possible selon vous de trouver un modèle économique à l’open data ?L’open data rend évidemment service aux citoyens, mais sont-ils prêts à payer pour cela ? Sans doute oui dans certains cas, notamment dans le champ du transport, si l’appli payante est très pratique. Pour se déplacer dans Rennes vous disposez de cinq ou six applis de transport, certaines gratuites mais pas forcément très bien faites, d’autres payantes peut-être plus pratiques d’utilisation. Par le bouche à oreille, les gens vont avoir envie de l’acheter. En revanche, les développeurs d’applis me disent ne pas pouvoir gagner de l’argent en vendant une appli à 1,50€. Quand le coût de fabrication s’élève de 10 à 40 000€, il est impossible de trouver un modèle économique sur une seule ville. Rennes compte en effet 100 000 habitants et tous ne prennent pas les transports en commun et n’ont pas un Smartphone. Pour que l’appli soit rentable, il faudrait la déployer sur 10 ou 15 villes, ce qui permettrait d’atteindre une taille de marché suffisante. Sinon, le modèle économique n’existe pas. On est loin des start up mirobolantes qui vont faire des millionnaires ! Au début de l’open data, les acteurs publics ont pu s’inquiéter qu’en donnant leurs données, elles n'enrichissent que des sociétés privées. Or 99% ne gagnent pas leur vie avec des applis. Le marché n’est pas mûr là-dessus. Aujourd’hui, le marché est impossible car la majorité des villes n’ont pas standardisé leurs données. L’adaptation d’une appli d’une ville à une autre est coûteuse. C’est une des promesses du web sémantique, de standardiser les données de façon à ce que les applications puissent toucher un marché plus grand.Alors, s’il n’y a pas de marché, pourquoi les gens continuent-ils à développer des applis en open data  ? Ils ont quand même des motivations : apprendre un langage informatique, valoriser son CV et peut-être trouver du boulot. Ce n’est pas parce qu’il n’y a pas de marché formellement identifié et bien cadré qu’il n’y a pas de motivation à produire des choses avec l’open data. L’open data reste encore largement un phénomène pour geek ; on voit bien que ceux qui devraient être les partenaires naturels de l’open data, à savoir les acteurs de la démocratie participative ou de l’économie sociale et solidaire, ne sont pas vraiment dans le coup. Comment intéresser un plus grand nombre de citoyens ?C’est tout à fait vrai. Un acteur de la démocratie participative nous disait que l’open data était un phénomène qui était passé complètement sous leurs radars, et qui, en plus, leur faisait peut-être même du tort car cela réoriente les politiques publiques, les élus croyant faire de la participation citoyenne en faisant de l’open data alors que ça n’a rien à voir. Certains acteurs de l’économie sociale et solidaire ne voient pas forcément d’un bon œil l’open data, ou en tout cas pas tel qu’il est utilisé par certains comme faire valoir de l’action publique. On est vraiment encore dans un monde de geeks. A tel point que même des associations prônant l’open data qui ont l’air d’être au plus proche des citoyens sont souvent en réalité des bandes de copains geeks, peu habitués à dialoguer avec le politique ou les citoyens. Ça ne veut pas dire que le travail que produit ces associations est mauvais, mais qu'il manque de contact de terrain et manque la cible du plus grand nombre.Alors, comment aller au-delà ? La principale piste réside dans l’animation de ces données. A la FING, on explique aux acteurs publics que cette phase d’animation est absolument indispensable. Qu’entendez-vous par animation ? Pour l’instant, on voit essentiellement des concours d’applis lancés par les collectivités publiques…Les concours font partie de ces animations, mais ce n’est pas suffisant. Pour l’instant, ils sont peut-être encore trop fléchés vers les geeks. Mais il pourrait y avoir des concours qui soient très centrés sur l’économie sociale et solidaire par exemple.Probablement que les acteurs publics doivent accentuer leur politique auprès des réutilisateurs qui ne sont pas des geeks. A Montpellier des choses très intéressantes se font dans ce sens. Les « cartoparties», collectes citoyennes de données permettant de cartographier l’accessibilité de la ville aux handicapés, ce n’est pas du tout une initiative geek ! Ils ont un partenariat avec une pharmacie qui prête à cette occasion des fauteuils roulants pour que les gens se rendent compte des difficultés quotidiennes des gens qui sont en fauteuil.A la FING, on a proposé la mise en place d’Infolabs, concept repris aux fablabs : il s’agit de prolonger au domaine de l’information l’esprit, l’efficacité, la créativité qui se développent dans les fablabs – ces espaces ouverts de prototypage rapide d'objet.Pour nous, la question des données mériterait d’avoir des lieux le plus ouvert possible dédiés à la formation, l’information, la capitalisation des connaissances et l’échange. Pourraient s’y tenir des conférences ou des hackatons, moments créatifs intenses où les gens travaillent ensemble autour d’un thème ou d’une problématique.Faire sortir le sujet de l’open data des mains des geeks, est un enjeu important, qui est bien identifié par les acteurs. Les gens qui fournissent de la donnée ouverte l’ont bien compris ; ils ont envie d’aller plus loin. Il y a différentes façons de le faire. Cela passe principalement par l’animation des territoires et des réseaux. Il n’y a pas toujours un travail en amont pour identifier les bonnes têtes de réseau sur un territoire pour expliquer ce qu’il est possible de faire, pour dialoguer. Jusqu’à présent, on s’est un peu facilement intéressé aux gens qui réclamaient spontanément les données. Aujourd’hui, il y a une prise en compte plus intéressante des non geeks. La Communauté urbaine de Bordeaux et l'AEC ont mené un travail très intéressant avec l’école de journalisme qui constitue un relais par rapport au grand public, pour décrypter et analyser l’importance des données. N’y a-t’il pas aussi un enjeu dans l’éditorialisation des données ? Ne peut-on pas sortir des applis et investir par l’exemple l’espace public ? Y a-t’il de nouvelles formes d’éditorialisation des données ?Tout à fait ! Il y a deux initiatives auxquelles je pense. Quand vous allez sur la page d’un jeu de données sur le portail de la région Provence Alpes Côte d’Azur (PACA), un lien est effectué vers des rapports, des documents, voire de la publicité qui ont pu être produits grâce à ces données. Du coup, cela matérialise l’usage des données, cela les rend plus familières ; on comprend à quoi elles servent à l’acteur public.En revanche, quelque chose n’a pas été fait et pourrait l’être assez facilement : dans ces portails open data, il est vrai un peu ésotérique, il serait intéressant d’avoir une éditorialisation qui facilite clairement l’acheminement des débutants. Pourquoi pas « un coin des débutants », ou alors « des données qui vous parlent », « des données faciles à comprendre » ? Je suis persuadé qu’on peut trouver un angle d’entrée plus grand public pour les portails, ce qui actuellement n’est pas tout à fait le cas. Certains essaient, en proposant en page d’accueil du portail, une image qui défile et valorise souvent des jeux de données faciles à comprendre (par exemple le jeu de données sur les prénoms qui existe à Rennes, Montpellier, Nantes, Paris, etc.). Mais c’est encore trop timide.Il existe un autre moyen très efficace : l’aide au développement des initiatives de crowdsourcing, comme OpenStreetMap, sur les territoires. Ça me paraît être une piste vraiment intéressante. Dans le cas d'OpenStreetMap, quand vous emmenez des néophytes sur le terrain et vous les faites cartographier les données géographiques, cela crée une vraie compréhension de la donnée, par ces travaux pratiques, qui peut être intéressante pour l’appréhension par le plus grand nombre.Simon Chignard a fait plusieurs expériences de collecte de données de transport avec les habitants, à Marseille, Nantes, etc. C’est ainsi que, par l’expérience, les gens réfléchissent à la question de l’information dans la ville. On parle de plus en plus d’une « ville servicielle ». Ne peut-on imaginer que dans cette ville servicielle, une information numérique qui facilite la ville, court sur les murs, les panneaux, le sol, dans l’espace public ?A cet égard, la Direction prospective du Grand Lyon avait proposé la création d’une « agence éditoriale  de l’espace public », que pensez-vous de cette idée ?Très belle idée ! D’autant que Lyon, la ville lumière, a une intéressante culture de ce point de vue là.À la FING, nous avons travaillé il y a quelques mois sur le tweety wall. Équivalent des sucettes Decaux, ce sont des écrans qui matérialisent l’information urbaine dans un rayon déterminé autour de chaque écran, en puisant notamment dans le flux de Twitter. Rennes a mené également plusieurs expériences avec des SMS Wall, permettant aux passant d'y poster leurs messages par SMS.Il existe aussi de belles expérimentations avec les écrans urbains communicants qui ont été réalisées à Marseille et à Montpellier et notamment une exploration historique de la ville en 3D : plus on s’approche de l’écran, plus la ville recule dans le passé. Le 5e écran de Bruno Marzloff raconte assez bien ces médias urbains dans la ville 2.0.Mais publier des données dans l’espace urbain pose des questions juridiques – l’affichage dans l’espace urbain est très réglementé – et des questions liées à l’éditorialisation, le tri et la modération des informations participatives.C’est une piste très intéressante, qui va progressivement gagner en importance, mais ce n’est pas la plus simple. Y a t’il des pistes plus simples d’exploitation de l’open data dans l’espace public ?La ville d’Orange est la première ville au monde, à ma connaissance, à avoir fait imprimer un plan de ville tout à fait classique, qui vient d’open street map. Autrement dit, le plan de la ville a été fait par les habitants. Ce plan est distribué à l'office du tourisme et en mairie. L’open data ce n’est pas toujours des manifestations avec roulements de tambour et trompette. Parfois, il y a des techniciens de collectivités qui, sans forcément afficher le terme d’open data, y vont ! Les élus d’Orange par exemple se sont très peu saisis de cette initiative, je pense qu’ils ne l’ont même pas compris.  C’est un plan papier, mais on pourrait imaginer que des écrans affichent ce plan dans la ville. De plus, il existe des dynamiques d’analyse. Les techniciens de la ville d’Orange ont fait développer par une petite société, 3liz, un outil qui leur permet de surveiller toutes les modifications effectuées dans open street map. Ils ne créent pas la donnée, quand ils constatent une erreur, ils contactent l’auteur ou font la correction eux-mêmes. Cela leur demande peu de travail mais leur permet d’avoir un plan de ville qui évolue très rapidement, fait par les gens qui sont sur le terrain. Est-ce qu’en dehors des applis, d’autres types de mises en forme des données se développent ?On focalise sur les applis, en particulier mobiles, alors qu’il se passe plein de choses. Je suis très surpris qu’il y ait peu d’alerte, sous forme de mél ou SMS. Par exemple, je suis persuadé que des gens apprécieraient de recevoir un SMS à chaque veille de sortie de la poubelle verte. L’open data apparaît comme un levier interne de modernisation pour les acteurs publics, qui aide au décloisonnement des services et au pilotage de l’action public ; il fait même évoluer les métiers des services urbains. Sont-ce des phénomènes que vous avez observés ?Très clairement, j’ai vu des services qui se parlaient peu se mettre autour d’une table et commencer à se raconter leurs données. C’est déjà inestimable ! Comme c’est un sujet naturellement transversal, l’open data crée de la transversalité et force les services à travailler ensemble.Beaucoup d’acteurs publics, dont le Département de Saône-et-Loire, nous disent que le projet open data a été pour eux un moyen de modernisation et de décloisonnement des services. La Banque Mondiale, une des premières organisations internationales à avoir ouvert ses données, l’a d’abord fait parce que c’était un moyen de décloisonner l’information en interne. L’open data peut aussi susciter des réticences voire des résistances : les données (et donc aussi les résultats) des services étant rendus publiques, les agents peuvent se sentir « fliqués »…Il peut y avoir ce genre de réactions, qui sont compréhensibles. Et en même temps, le travail d’animation est très largement interne. Il est aussi de faire se rencontrer l’interne avec l’externe pour montrer la façon dont sont valorisées les données. Des agents qui voient des données sur lesquelles ils travaillent tous les jours, réutilisées dans des applis à l’extérieur, c’est drôlement valorisant ! Ils réalisent que des gens exploitent directement la matière première qu’ils produisent.C’est important de travailler avec les agents pour leur donner des exemples positifs de ce qui pourrait être fait. L’objectif n’est pas un flicage. Le Département de Saône-et-Loire a mis en place un comité d’éthique des données, c’est intéressant. Annoncer dès le départ qu’on va travailler la question éthique, qu’on va réfléchir à ce que la question des données provoque, qu’on va écouter les agents, cela fait partie du processus de bonne appropriation, de décrispation et d’explication de l’open data. Il faut aussi savoir dire de temps en temps : non, il n’est pas intéressant de publier maintenant cette donnée-là. Est-ce que cette préoccupation « éthique » ne rejoint pas la position du Grand Lyon sur l’open data, celle d'une ouverture raisonnée des données, si possible dans le cadre d'animations partenariales, et avec le souci d'une maîtrise des politiques publiques ?Je ne peux qu’applaudir à une telle position ! Mais il ne faudrait pas croire que les autres acteurs publics ont publié à tort et à travers leurs données. C’est vrai que certains ont fait un peu de remplissage. Mais la plupart ont traité des thèmes en cohérence avec leurs politiques publiques. C’est le cas à la CUB, mais aussi à  Rennes qui a commencé avec deux problématiques fortes qui sont au cœur de ses politiques publiques actuelles : les services pratiques apportés aux Rennais et le transport.Mais il n’y a certainement pas assez d’intégration claire de l’open data dans les démarches de certaines politiques publiques. La cohérence avec les politiques publiques relève-t’elle d’une forme d’éthique  ?Je ne sais pas. Il ne faut pas non plus négliger les questions de sérendipité. Au tout début, il y a deux ans et demi, on disait aux acteurs : « ne vous posez pas trop de question, commencez par publier des données ; au pire, allez-y avec un peu n’importe quoi et on verra. C’est important de roder votre process de publication, de voir comment les données sont accueillies, comment les gens réagissent ». C’est intéressant car cela a permis de mettre le doigt sur des problématiques qui faisaient partie des politiques publiques mais auxquelles les techniciens n’avaient pas forcément pensé. Il faut se laisser un peu d’effet de surprise. Les acteurs publics disent souvent : « On ne s’attendait pas à voir sortir telle ou telle chose ». Quand les gens ont commencé à travailler sur le handicap à Rennes, un dialogue s’est engagé et c’est ainsi que Rennes a compris que la pente des rues pouvait être une donnée très utile. Certaines données ont ainsi été rajoutée, qui ont amélioré l’appli Handimap. Il faut aussi accepter de se laisser un peu surprendre et de ne pas tout maîtriser, tout prévoir à l’avance.L’open data est un processus d’innovation ouverte, c’est donc un processus itératif où l’on va forcément tomber sur des surprises. Vouloir planifier ou coller l’open data à une politique publique, c’est une très bonne chose, mais le fait de se laisser surprendre ou dérouter, peut être un vrai vecteur d’innovation pour l’action publique ou le territoire. Qu’en est-il de l’intégration de l’open data dans des grands projets urbains ? N’est-ce pas un élément qui pourrait figurer, par exemple, dans le projet de réinvention de la Part-Dieu à Lyon ?C’est une thématique qui peut être un levier très important à la fois pour les projets urbains et les territoires. C’est vrai qu’aujourd’hui, il y a très peu de projets open data liés à une opération de rénovation urbaine ou à un grand événement urbain. Le seul auquel je pense, mais ce n’est pas tout à fait un projet urbain, c’est Marseille-Provence 2013. Là il y a une vraie dynamique. Marseille-Provence 2013 a fortement contribué à lancer le projet open data du territoire. Beaucoup des jeux open data que la Région a pu publier ont un lien avec cet événement. Tout au long de l’année, beaucoup de travaux de terrain vont être effectués avec les étudiants, les acteurs de la culture, les journalistes, etc. autour des données liées à l’événement capitale.A part ça, je ne connais pas de projet de rénovation qui aurait pu se saisir de l’open data. On pourrait imaginer que pour certains grands projets urbains, par exemple celui de la Part-Dieu, l’acteur public puisse montrer l’exemple et essayer, sur ce territoire particulier, de faire un effort beaucoup plus important de production de données. Il faudrait aussi que les acteurs privés jouent le jeu en ouvrant un maximum de données. Il s’agit d’aller voir les opérateurs (Orange, Véolia, etc.) et leur dire : « on vous demande de nous aider à trouver une solution à la problématique de ce quartier. On vous demande, en mode expérimental, sur un territoire donné, d’ouvrir vos données. Vous, cela vous permet d’étudier des manières de libérer vos données, nous, cela nous permet de comprendre ce que vous avez. Aux gens du territoire, de mieux comprendre leur quartier, etc.» Là, je pense qu’il y a vraiment une carte à jouer, de façon à libérer un maximum de potentiel d’un projet de rénovation urbaine. Pour l’instant, c’est dommage, ça n’a pas été le cas. Il y a des petites discussions actuellement autour d’un projet de rénovation urbaine à Nantes, mais ce n’est pas allé très loin. Si le Grand Lyon avait envie d’expérimenter ça autour d’un projet urbain, je trouverais ça vraiment très intéressant ! Ce serait un creuset d’expérimentations locales duquel on pourrait tirer des enseignements et les généraliser peut-être au reste des territoires. L’open data peut susciter l’émergence de nouveaux services publics portés par des acteurs privés ou indépendants. Est-ce de nature à concurrencer le cœur des missions publiques, à dessaisir les services d’une partie de leur vocation ? Quelles conséquences cela peut-il avoir, notamment sur les services urbains, leur « culture », leur positionnement ?C’est une question qu’on se pose depuis plus de deux ans. Daniel Kaplan avait publié un article sur le sujet, intitulé « L’open data et après ? ». On s’interrogeait sur le fait que l’open data pouvait, paradoxalement, faire baisser le nombre de services publics. Et si l’ouverture des données contribuait paradoxalement à moins de données ? En ouvrant des données, vous créez des services, et en même temps des entreprises qui peuvent avoir ces données et faire concurrence aux services publics…Aujourd’hui, on n’est pas capables de dire : l’ouverture de telles données a provoqué le retrait de tel service public. J’aimerais voir des exemples concrets. Je ne suis pas sûr que le marché force le service public à se retirer. Je crois que c’est surtout une façon d’externaliser la créativité ; de créer des choses que la collectivité pourra le cas échéant un jour reprendre à son compte s’il y a un véritable enjeu public. Car l’objectif ultime c’est bien la collectivité, le bien public. C’est à l’acteur public d’arbitrer entre des situations où l’on doit intervenir, ou au contraire où l’on a tout intérêt à laisser jouer l'initiative privée et la libre concurrence. Je ne suis pas sûr qu’il y ait un vrai sujet là dessus ; on l’a identifié comme une possibilité. L’open data aura t’il contribué à vraiment faire bouger les lignes de l’action publique ? On n’aura pas le recul avant 4 ou 5 ans au moins. Pour une collectivité publique comment présentez-vous ou hiérarchisez-vous les avantages de l’open data : s’agit avant tout d’un levier de modernisation en interne, de développement économique, de démocratie participative ?Je ne pense qu’il y a ait une hiérarchie très établie. Hormis peut-être sur les attentes économiques qui ont probablement été survalorisées. Je crois qu’aujourd’hui ce n’est pas l’enjeu ou le bénéfice principal. Le premier bénéfice, c’est la modernisation interne des collectivités. C’est ensuite une certaine externalisation de projets qui n’avaient pas forcément beaucoup de sens à être traités en interne : est-ce la vocation d’un acteur public de faire des applis mobile pour les transports ?Il y a enfin la question de la co-innovation qui me paraît très importante. Un acteur public a du mal à innover tout seul ; en ouvrant des données, il voit sortir des usages auxquels il ne s’attendait pas, qui participent à l’innovation du territoire. Cela ne veut pas dire que cela crée des entreprises tout de suite, mais cela leur fait remonter des opportunités ; cela permet d’observer, en réel, ce qui pourrait devenir un service public.Rennes s’interroge sur la façon d’aider les gens qui travaillent sur l’accessibilité dans la ville via l’open data. Ce sont des manières de co-innover avec la population qui montrent des exemples, des chemins. Ces pistes d’innovation ont peut-être aujourd’hui du mal à passer dans l’économie, mais elles donnent des exemples qui, à un moment ou un autre, vont être appropriés par des acteurs de la vie économique.Je vois aussi un autre bénéfice lié à la co-innovation, celui d’une nouvelle posture de l’acteur public. Elle  consiste à accepter de ne pas être le seul maître, directeur ou aménageur des politiques publiques de la vie de son territoire, pour accepter humblement d'écouter ce que les habitants demandent, ce que racontent les applis open data. C’est une posture nouvelle pour les acteurs publics, pas toujours facile à adopter. Je trouve globalement que les acteurs publics s’en sortent pas mal du tout. Je vois des agents assez enthousiastes, assez fiers d’un certain nombre de projets. Ils jouent le jeu de l’écoute. Cela rend plus concret la co-fabrication des territoires avec les habitants. Cela me paraît important pour les collectivités publiques et rejoint un enjeu modernisation de l’action publique.Enfin, dernier avantage : grâce à l’open data, on assiste à la montée en compétence du territoire, avec des habitants plus outillés, plus intelligents, qui disposent de davantage de capacitation. 